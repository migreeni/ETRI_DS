{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b7bebf",
   "metadata": {},
   "source": [
    "# dwt 적용해서 feature 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc8080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717a7f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mACStatus with shape (939896, 3)\n",
      "Loaded mScreenStatus with shape (939653, 3)\n",
      "Loaded mUsageStats with shape (45197, 3)\n",
      "Loaded mActivity with shape (961062, 3)\n",
      "Loaded mBle with shape (21830, 3)\n",
      "Loaded mWifi with shape (76336, 3)\n",
      "Loaded wHr with shape (382918, 3)\n",
      "Loaded wPedo with shape (748100, 9)\n",
      "Loaded mGps with shape (800611, 3)\n",
      "Loaded mLight with shape (96258, 3)\n",
      "Loaded wLight with shape (633741, 3)\n",
      "Loaded mAmbience with shape (476577, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path for data folder\n",
    "DATA_DIR = \"../data/\"\n",
    "\n",
    "# Main data item list\n",
    "file_names = [\n",
    "    \"mACStatus\", \"mScreenStatus\", \"mUsageStats\", \"mActivity\", \"mBle\", \"mWifi\",\n",
    "    \"wHr\", \"wPedo\", \"mGps\", \"mLight\",\"wLight\", \"mAmbience\"\n",
    "]\n",
    "\n",
    "data_files = {name: os.path.join(DATA_DIR, f\"ch2025_{name}.parquet\") for name in file_names}\n",
    "\n",
    "dfs = {}\n",
    "for name, file_path in data_files.items():\n",
    "    dfs[name] = pd.read_parquet(file_path)\n",
    "    globals()[name] = dfs[name]\n",
    "    print(f\"Loaded {name} with shape {dfs[name].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a27c8",
   "metadata": {},
   "source": [
    "### 일단 간단하게 wLight dwt 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c5aeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyWavelets\n",
      "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /home/wonjun/.local/lib/python3.10/site-packages (from PyWavelets) (1.24.3)\n",
      "Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyWavelets\n",
      "Successfully installed PyWavelets-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335399a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   level_0_mean  level_0_std  level_0_energy  level_1_mean  level_1_std  \\\n",
      "0   1896.855697  3468.180769    1.050090e+10    -77.191514  2563.281570   \n",
      "1   1269.319542  3708.348697    2.020237e+10    -58.556863  2071.915189   \n",
      "2   1249.935703  3211.219235    1.123306e+10    -44.914753  1711.498931   \n",
      "3   1562.229941  3980.721287    1.777468e+10     59.418617  1897.019771   \n",
      "4   2187.230936  5155.305936    2.552798e+10    -18.043144  2808.941594   \n",
      "\n",
      "   level_1_energy  level_2_mean  level_2_std  level_2_energy  level_3_mean  \\\n",
      "0    4.419321e+09      0.685512  2250.379328    6.770846e+09      2.734507   \n",
      "1    5.649584e+09     28.815372  1420.826885    5.299376e+09    -23.675415   \n",
      "2    2.772959e+09     60.081667  1552.879161    4.552357e+09      8.183103   \n",
      "3    3.501353e+09     68.298851  1990.576473    7.684194e+09     32.763466   \n",
      "4    6.422849e+09     45.653551  2561.705812    1.064093e+10     26.037351   \n",
      "\n",
      "   ...  level_4_mean  level_4_std  level_4_energy  level_5_mean  level_5_std  \\\n",
      "0  ...     27.009144  1827.365777    1.780217e+10    -23.145428  1387.797640   \n",
      "1  ...      4.460262   946.632224    9.389676e+09     17.452703   990.190643   \n",
      "2  ...    -14.830765   981.225032    7.243855e+09      4.752362  1002.550965   \n",
      "3  ...     16.606641  1835.694274    2.604374e+10     -9.547962  1620.369074   \n",
      "4  ...     26.738470  1861.759014    2.240633e+10      1.634845  1735.352754   \n",
      "\n",
      "   level_5_energy  level_6_mean  level_6_std  level_6_energy  subject_id  \n",
      "0    2.052320e+10     10.487185  1363.602799    3.960783e+10        id01  \n",
      "1    2.054640e+10      6.760259   824.548545    2.848346e+10        id02  \n",
      "2    1.511416e+10     -5.983526   843.428638    2.139061e+10        id03  \n",
      "3    4.056424e+10    -10.185328  1355.992373    5.680480e+10        id04  \n",
      "4    3.890796e+10     -5.030875  1625.237011    6.823582e+10        id05  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "(10, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1033049/4131239235.py:21: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  values = grp['w_light'].fillna(method='ffill').fillna(0).values\n"
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "\n",
    "# ensure timestamp is datetime and sort by subject and time\n",
    "wLight['timestamp'] = pd.to_datetime(wLight['timestamp'])\n",
    "wLight = wLight.sort_values(['subject_id', 'timestamp'])\n",
    "\n",
    "# function to extract DWT features from a 1D array\n",
    "def extract_dwt_features(signal, wavelet='db4', level=6):\n",
    "    coeffs = pywt.wavedec(signal, wavelet=wavelet, level=level)\n",
    "    feats = {}\n",
    "    # for each level (approximation + details) compute mean, std, energy\n",
    "    for idx, c in enumerate(coeffs):\n",
    "        feats[f'level_{idx}_mean']   = np.mean(c)\n",
    "        feats[f'level_{idx}_std']    = np.std(c)\n",
    "        feats[f'level_{idx}_energy'] = np.sum(c**2)\n",
    "    return feats\n",
    "\n",
    "# group by subject, fill gaps, extract features\n",
    "feature_rows = []\n",
    "for subj, grp in wLight.groupby('subject_id'):\n",
    "    values = grp['w_light'].fillna(method='ffill').fillna(0).values\n",
    "    row = extract_dwt_features(values)\n",
    "    row['subject_id'] = subj\n",
    "    feature_rows.append(row)\n",
    "\n",
    "# assemble into DataFrame\n",
    "features_df = pd.DataFrame(feature_rows)\n",
    "print(features_df.head())\n",
    "print(features_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  w_light        date\n",
      "0       id01 2024-06-26 12:17:00    633.0  2024-06-26\n",
      "1       id01 2024-06-26 12:18:00    483.0  2024-06-26\n",
      "2       id01 2024-06-26 12:19:00    541.0  2024-06-26\n",
      "3       id01 2024-06-26 12:20:00    547.0  2024-06-26\n",
      "4       id01 2024-06-26 12:21:00    547.0  2024-06-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1033049/684432306.py:30: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  .resample('1T').mean()\n",
      "/home/wonjun/.conda/envs/wonjun_base/lib/python3.10/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   level_0_mean  level_0_std  level_0_energy  level_1_mean  level_1_std  \\\n",
      "0   2319.716888  1993.061284    1.590075e+08    220.529958   857.949949   \n",
      "1   1487.508117  3064.055081    3.364323e+08   -380.241503  2156.959740   \n",
      "2   2043.725484  4345.636720    6.687798e+08    496.916154  3143.140541   \n",
      "3    443.503950   762.056177    2.176791e+07    -15.674754   227.526787   \n",
      "4    643.657139  1392.467875    6.824458e+07     58.644312   399.099776   \n",
      "\n",
      "   level_1_energy  level_2_mean  level_2_std  level_2_energy  level_3_mean  \\\n",
      "0    1.334010e+07   -136.793320   868.805762    2.165900e+07   -105.754601   \n",
      "1    1.391147e+08    238.336705  1913.642816    1.896605e+08   -102.318272   \n",
      "2    2.936615e+08    626.101028  3516.648909    6.506999e+08   -266.706257   \n",
      "3    1.456396e+06     -5.185987    99.312189    4.944903e+05     -8.925586   \n",
      "4    4.718874e+06      8.353223   630.773780    2.029521e+07    -14.666764   \n",
      "\n",
      "   ...  level_4_std  level_4_energy  level_5_mean  level_5_std  \\\n",
      "0  ...   356.326837    1.194304e+07     52.702714   833.287429   \n",
      "1  ...   809.842478    1.236615e+08    -14.868727   522.140233   \n",
      "2  ...  3133.601351    1.799755e+09    134.645538  2668.841341   \n",
      "3  ...    58.401257    6.191852e+05     -1.593556    32.170706   \n",
      "4  ...   277.952579    1.447844e+07     -9.967894   292.133223   \n",
      "\n",
      "   level_5_energy  level_6_mean  level_6_std  level_6_energy  subject_id  \\\n",
      "0    1.261833e+08     58.040194   824.356485    2.424410e+08        id01   \n",
      "1    9.931795e+07    -18.353436   388.377004    1.091473e+08        id01   \n",
      "2    2.563563e+09   -109.360221  2543.240238    4.613782e+09        id01   \n",
      "3    3.672728e+05      0.006044    18.745470    2.466777e+05        id01   \n",
      "4    3.118603e+07     -9.289212   205.092875    3.047400e+07        id01   \n",
      "\n",
      "         date  \n",
      "0  2024-06-26  \n",
      "1  2024-06-27  \n",
      "2  2024-06-28  \n",
      "3  2024-06-29  \n",
      "4  2024-06-30  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(664, 23)\n"
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "\n",
    "# 1) timestamp를 datetime으로 변환하고 정렬\n",
    "wLight['timestamp'] = pd.to_datetime(wLight['timestamp'])\n",
    "wLight = wLight.sort_values(['subject_id', 'timestamp'])\n",
    "\n",
    "print(wLight.head())\n",
    "# 2) 날짜(date) 컬럼 추가\n",
    "wLight['date'] = wLight['timestamp'].dt.date\n",
    "\n",
    "# 3) DWT feature 추출 함수 (예시는 db4, 최대 6레벨)\n",
    "def extract_dwt_features(signal, wavelet='db4', level=6):\n",
    "    coeffs = pywt.wavedec(signal, wavelet=wavelet, level=level)\n",
    "    feats = {}\n",
    "    for idx, c in enumerate(coeffs):\n",
    "        feats[f'level_{idx}_mean']   = np.mean(c)\n",
    "        feats[f'level_{idx}_std']    = np.std(c)\n",
    "        feats[f'level_{idx}_energy'] = np.sum(c**2)\n",
    "    return feats\n",
    "\n",
    "# 4) subject_id × date별로 묶어서 feature 뽑기\n",
    "feature_rows = []\n",
    "for (subj, day), grp in wLight.groupby(['subject_id', 'date']):\n",
    "    # grp을 timestamp 기준으로 인덱싱하고 나서 w_light 컬럼을 꺼냅니다.\n",
    "    vals = (\n",
    "        grp\n",
    "        .set_index('timestamp')['w_light']\n",
    "        .resample('1T').mean()\n",
    "        .ffill().fillna(0)\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    feats = extract_dwt_features(vals)\n",
    "    feats['subject_id'] = subj\n",
    "    feats['date']       = day\n",
    "    feature_rows.append(feats)\n",
    "\n",
    "# 5) DataFrame 조립\n",
    "daily_features = pd.DataFrame(feature_rows)\n",
    "print(daily_features.head())\n",
    "print(daily_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13950d0f",
   "metadata": {},
   "source": [
    "# DWT 적용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f1673de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) mUsageStats\n",
    "prep_mUsageStats = mUsageStats[['subject_id', 'timestamp']].copy()\n",
    "prep_mUsageStats['total_usage_time'] = mUsageStats['m_usage_stats'].apply(\n",
    "    lambda lst: sum(d.get('total_time', 0) for d in lst)\n",
    ")\n",
    "\n",
    "# 2) wHr\n",
    "prep_wHr = wHr[['subject_id', 'timestamp']].copy()\n",
    "prep_wHr['avg_heart_rate'] = wHr['heart_rate'].apply(\n",
    "    lambda lst: np.mean(lst) if len(lst) > 0 else np.nan\n",
    ")\n",
    "\n",
    "# 3) mBle\n",
    "prep_mBle = mBle[['subject_id', 'timestamp']].copy()\n",
    "prep_mBle['wb_rssi'] = mBle['m_ble'].apply(\n",
    "    lambda lst: sum(np.exp(d.get('rssi', 0) / 10) for d in lst)\n",
    ")\n",
    "\n",
    "# 4) mWifi\n",
    "prep_mWifi = mWifi[['subject_id', 'timestamp']].copy()\n",
    "prep_mWifi['ww_rssi'] = mWifi['m_wifi'].apply(\n",
    "    lambda lst: sum(np.exp(d.get('rssi', 0) / 10) for d in lst)\n",
    ")\n",
    "\n",
    "# 5) wLight (just copy)\n",
    "prep_wLight = wLight.copy()\n",
    "\n",
    "# 6) mGps\n",
    "def avg_gps(arr):\n",
    "    if len(arr) == 0:\n",
    "        return pd.Series({'avg_alt': np.nan, 'avg_lat': np.nan, 'avg_long': np.nan, 'avg_speed': np.nan})\n",
    "    alts = [d.get('altitude', np.nan) for d in arr]\n",
    "    lats = [d.get('latitude', np.nan) for d in arr]\n",
    "    longs = [d.get('longitude', np.nan) for d in arr]\n",
    "    speeds = [d.get('speed', np.nan) for d in arr]\n",
    "    return pd.Series({\n",
    "        'avg_alt': np.nanmean(alts),\n",
    "        'avg_lat': np.nanmean(lats),\n",
    "        'avg_long': np.nanmean(longs),\n",
    "        'avg_speed': np.nanmean(speeds),\n",
    "    })\n",
    "\n",
    "prep_mGps = mGps[['subject_id', 'timestamp']].copy()\n",
    "gps_avgs = mGps['m_gps'].apply(avg_gps)\n",
    "prep_mGps = pd.concat([prep_mGps, gps_avgs], axis=1)\n",
    "\n",
    "# 7) wPedo\n",
    "prep_wPedo = wPedo[['subject_id', 'timestamp', 'distance', 'speed']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d90f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1033049/30519956.py:47: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  ts = grp.set_index('timestamp')[col].resample('1T').mean().fillna(0).values\n",
      "/tmp/ipykernel_1033049/30519956.py:47: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  ts = grp.set_index('timestamp')[col].resample('1T').mean().fillna(0).values\n",
      "/home/wonjun/.conda/envs/wonjun_base/lib/python3.10/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 3 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1033049/30519956.py:47: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  ts = grp.set_index('timestamp')[col].resample('1T').mean().fillna(0).values\n",
      "/home/wonjun/.conda/envs/wonjun_base/lib/python3.10/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 3 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1033049/30519956.py:47: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  ts = grp.set_index('timestamp')[col].resample('1T').mean().fillna(0).values\n",
      "/home/wonjun/.conda/envs/wonjun_base/lib/python3.10/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 3 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1033049/30519956.py:47: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  ts = grp.set_index('timestamp')[col].resample('1T').mean().fillna(0).values\n",
      "/home/wonjun/.conda/envs/wonjun_base/lib/python3.10/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 3 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1033049/30519956.py:47: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  ts = grp.set_index('timestamp')[col].resample('1T').mean().fillna(0).values\n",
      "/home/wonjun/.conda/envs/wonjun_base/lib/python3.10/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 3 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1033049/30519956.py:47: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  ts = grp.set_index('timestamp')[col].resample('1T').mean().fillna(0).values\n",
      "/home/wonjun/.conda/envs/wonjun_base/lib/python3.10/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 3 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id        date  total_usage_time_lev0_mean  \\\n",
      "0       id01  2024-06-26               142850.553034   \n",
      "1       id01  2024-06-27               111931.971924   \n",
      "2       id01  2024-06-28               109725.298833   \n",
      "3       id01  2024-06-29                96803.554352   \n",
      "4       id01  2024-06-30               152565.531960   \n",
      "\n",
      "   total_usage_time_lev0_std  total_usage_time_lev0_energy  \\\n",
      "0              320174.917383                  1.044805e+13   \n",
      "1              155658.006840                  6.542956e+12   \n",
      "2              141429.307699                  4.678116e+12   \n",
      "3              131253.540690                  3.351401e+12   \n",
      "4              204423.231830                  8.588593e+12   \n",
      "\n",
      "   total_usage_time_lev1_mean  total_usage_time_lev1_std  \\\n",
      "0                16868.787990              195746.453812   \n",
      "1               -10115.412519              225115.986414   \n",
      "2                -3088.248837              207698.429065   \n",
      "3                 7762.613261              182339.072653   \n",
      "4               -24755.793043              239793.620558   \n",
      "\n",
      "   total_usage_time_lev1_energy  total_usage_time_lev2_mean  \\\n",
      "0                  3.281105e+12                 8393.429136   \n",
      "1                  9.038756e+12                -4006.069624   \n",
      "2                  6.299634e+12                 -544.240020   \n",
      "3                  4.196782e+12                 2592.374962   \n",
      "4                  7.671026e+12                 6500.473761   \n",
      "\n",
      "   total_usage_time_lev2_std  total_usage_time_lev2_energy  \\\n",
      "0              180177.890292                  5.303127e+12   \n",
      "1              185136.200391                  1.200201e+13   \n",
      "2              181198.161862                  9.357425e+12   \n",
      "3              145464.131772                  5.185801e+12   \n",
      "4              212958.848610                  1.171158e+13   \n",
      "\n",
      "   total_usage_time_lev3_mean  total_usage_time_lev3_std  \\\n",
      "0                53342.197715              185288.665550   \n",
      "1                54911.301801              195693.536418   \n",
      "2                56390.708911              186457.968055   \n",
      "3                45834.472503              153057.705073   \n",
      "4                62640.764456              207012.781018   \n",
      "\n",
      "   total_usage_time_lev3_energy  \n",
      "0                  1.185955e+13  \n",
      "1                  2.866998e+13  \n",
      "2                  2.140182e+13  \n",
      "3                  1.235529e+13  \n",
      "4                  2.381008e+13  \n",
      "(690, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "# 7개의 prep_ 데이터프레임을 딕셔너리에 모아둡니다.\n",
    "prep_dfs = {\n",
    "    'mUsageStats': prep_mUsageStats,\n",
    "    'wHr':          prep_wHr,\n",
    "    'mBle':         prep_mBle,\n",
    "    'mWifi':        prep_mWifi,\n",
    "    'wLight':       prep_wLight,\n",
    "    'mGps':         prep_mGps,\n",
    "    'wPedo':        prep_wPedo\n",
    "}\n",
    "\n",
    "# 1) DWT feature extraction 함수\n",
    "def extract_dwt_features(signal, wavelet='db4', level=6):\n",
    "    coeffs = pywt.wavedec(signal, wavelet=wavelet, level=level)\n",
    "    feats = {}\n",
    "    for idx, c in enumerate(coeffs):\n",
    "        feats[f'lev{idx}_mean']   = np.mean(c)\n",
    "        feats[f'lev{idx}_std']    = np.std(c)\n",
    "        feats[f'lev{idx}_energy'] = np.sum(c**2)\n",
    "    return feats\n",
    "\n",
    "# 2) 각 데이터프레임별로 사용할 DWT 레벨 지정 (튜닝 가능)\n",
    "level_list = [3,3,3,3,3,3,3]\n",
    "\n",
    "daily_features = {}\n",
    "\n",
    "for (name, df), lvl in zip(prep_dfs.items(), level_list):\n",
    "    # 3) timestamp → datetime으로 변환 & date 컬럼 추가\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values(['subject_id', 'timestamp'])\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "    # 4) numeric 컬럼만 골라 subject_id 제외\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_cols = [c for c in numeric_cols if c != 'subject_id']\n",
    "\n",
    "    # 5) 그룹별로 DWT 피처 뽑아서 리스트에 저장\n",
    "    feature_rows = []\n",
    "    for (subj, day), grp in df.groupby(['subject_id', 'date']):\n",
    "        row = {'subject_id': subj, 'date': day}\n",
    "        for col in numeric_cols:\n",
    "            # 1분 단위 리샘플링 평균 → 누락치는 0으로 채움\n",
    "            ts = grp.set_index('timestamp')[col].resample('1T').mean().fillna(0).values\n",
    "            feats = extract_dwt_features(ts, level=lvl)\n",
    "            # 컬럼명에 접두어 붙이기\n",
    "            for k, v in feats.items():\n",
    "                row[f'{col}_{k}'] = v\n",
    "        feature_rows.append(row)\n",
    "\n",
    "    # 6) DataFrame으로 변환해서 저장\n",
    "    daily_features[name] = pd.DataFrame(feature_rows)\n",
    "\n",
    "# 7) 샘플: wLight 일별 DWT 피처 확인\n",
    "print(daily_features['mUsageStats'].head())\n",
    "print(daily_features['mUsageStats'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97d33519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id        date  transition_count  act_0_count  act_0_ratio  \\\n",
      "0       id01  2024-06-26                32           89     0.125176   \n",
      "1       id01  2024-06-27                39          211     0.146528   \n",
      "2       id01  2024-06-28                40          161     0.111806   \n",
      "3       id01  2024-06-29                27           95     0.065972   \n",
      "4       id01  2024-06-30                26          199     0.138194   \n",
      "\n",
      "   act_1_count  act_1_ratio  act_2_count  act_2_ratio  act_3_count  \\\n",
      "0            1     0.001406            0          0.0          478   \n",
      "1            0     0.000000            0          0.0          880   \n",
      "2            1     0.000694            0          0.0         1241   \n",
      "3            0     0.000000            0          0.0         1320   \n",
      "4            0     0.000000            0          0.0         1229   \n",
      "\n",
      "   act_3_ratio  act_4_count  act_4_ratio  act_5_count  act_5_ratio  \\\n",
      "0     0.672293          112     0.157525            0          0.0   \n",
      "1     0.611111          318     0.220833            0          0.0   \n",
      "2     0.861806            1     0.000694            0          0.0   \n",
      "3     0.916667            0     0.000000            0          0.0   \n",
      "4     0.853472            0     0.000000            0          0.0   \n",
      "\n",
      "   act_7_count  act_7_ratio  act_8_count  act_8_ratio  \n",
      "0           31     0.043601            0          0.0  \n",
      "1           31     0.021528            0          0.0  \n",
      "2           36     0.025000            0          0.0  \n",
      "3           25     0.017361            0          0.0  \n",
      "4           12     0.008333            0          0.0  \n",
      "(700, 19)\n",
      "  subject_id        date  A capella_prob_sum  \\\n",
      "0       id01  2024-06-26                 0.0   \n",
      "1       id01  2024-06-27                 0.0   \n",
      "2       id01  2024-06-28                 0.0   \n",
      "3       id01  2024-06-29                 0.0   \n",
      "4       id01  2024-06-30                 0.0   \n",
      "\n",
      "   Accelerating, revving, vroom_prob_sum  Accordion_prob_sum  \\\n",
      "0                               4.333376                 0.0   \n",
      "1                               0.000000                 0.0   \n",
      "2                               0.000000                 0.0   \n",
      "3                               0.000000                 0.0   \n",
      "4                               0.000000                 0.0   \n",
      "\n",
      "   Acoustic guitar_prob_sum  Afrobeat_prob_sum  Air brake_prob_sum  \\\n",
      "0                       0.0                0.0                 0.0   \n",
      "1                       0.0                0.0                 0.0   \n",
      "2                       0.0                0.0                 0.0   \n",
      "3                       0.0                0.0                 0.0   \n",
      "4                       0.0                0.0                 0.0   \n",
      "\n",
      "   Air conditioning_prob_sum  Air horn, truck horn_prob_sum  ...  \\\n",
      "0                    0.01064                       0.069598  ...   \n",
      "1                    0.00000                       0.000000  ...   \n",
      "2                    0.00000                       0.000000  ...   \n",
      "3                    0.00000                       0.000000  ...   \n",
      "4                    0.00000                       0.000000  ...   \n",
      "\n",
      "   Wind noise (microphone)_prob_sum  Wood_prob_sum  Wood block_prob_sum  \\\n",
      "0                          0.100864       0.372201                  0.0   \n",
      "1                          0.000000       0.000000                  0.0   \n",
      "2                          0.116728       0.000000                  0.0   \n",
      "3                          0.000000       0.000000                  0.0   \n",
      "4                          0.000000       0.000000                  0.0   \n",
      "\n",
      "   Writing_prob_sum  Yell_prob_sum  Yip_prob_sum  Yodeling_prob_sum  \\\n",
      "0          0.070800            0.0           0.0                0.0   \n",
      "1          0.000000            0.0           0.0                0.0   \n",
      "2          0.000000            0.0           0.0                0.0   \n",
      "3          0.035868            0.0           0.0                0.0   \n",
      "4          0.000000            0.0           0.0                0.0   \n",
      "\n",
      "   Zing_prob_sum  Zipper (clothing)_prob_sum  Zither_prob_sum  \n",
      "0            0.0                     0.01081              0.0  \n",
      "1            0.0                     0.00000              0.0  \n",
      "2            0.0                     0.00000              0.0  \n",
      "3            0.0                     0.00000              0.0  \n",
      "4            0.0                     0.00000              0.0  \n",
      "\n",
      "[5 rows x 519 columns]\n",
      "(700, 519)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- prep_mActivity 생성 ---\n",
    "# 1. timestamp → datetime, date 컬럼 추가\n",
    "mActivity['timestamp'] = pd.to_datetime(mActivity['timestamp'])\n",
    "mActivity = mActivity.sort_values(['subject_id', 'timestamp'])\n",
    "mActivity['date'] = mActivity['timestamp'].dt.date\n",
    "\n",
    "# 2. 사용할 activity 코드 목록 (0,1,2,3,4,5,7,8)\n",
    "activity_codes = [0,1,2,3,4,5,7,8]\n",
    "\n",
    "rows = []\n",
    "for (subj, day), grp in mActivity.groupby(['subject_id','date']):\n",
    "    total = len(grp)\n",
    "    counts = grp['m_activity'].value_counts().reindex(activity_codes, fill_value=0)\n",
    "    ratios = counts / total\n",
    "    # transition count: 연속된 activity 값이 바뀐 횟수\n",
    "    trans = (grp['m_activity'].shift() != grp['m_activity']).sum() - 1  # 첫 비교 제외\n",
    "    row = {\n",
    "        'subject_id': subj,\n",
    "        'date':       day,\n",
    "        'transition_count': int(trans)\n",
    "    }\n",
    "    # 각 코드별 count, ratio 추가\n",
    "    for code in activity_codes:\n",
    "        row[f'act_{code}_count'] = int(counts[code])\n",
    "        row[f'act_{code}_ratio'] = float(ratios[code])\n",
    "    rows.append(row)\n",
    "\n",
    "prep_mActivity = pd.DataFrame(rows)\n",
    "print(prep_mActivity.head())\n",
    "print(prep_mActivity.shape)\n",
    "\n",
    "\n",
    "# --- prep_mAmbience 생성 ---\n",
    "# 1. timestamp → datetime, date 컬럼 추가\n",
    "mAmbience['timestamp'] = pd.to_datetime(mAmbience['timestamp'])\n",
    "mAmbience = mAmbience.sort_values(['subject_id','timestamp'])\n",
    "mAmbience['date'] = mAmbience['timestamp'].dt.date\n",
    "\n",
    "# 2. 전체 고유 label pool 추출\n",
    "label_pool = set()\n",
    "for lst in mAmbience['m_ambience']:\n",
    "    for label, prob in lst:\n",
    "        label_pool.add(label)\n",
    "label_pool = sorted(label_pool)\n",
    "\n",
    "rows = []\n",
    "for (subj, day), grp in mAmbience.groupby(['subject_id','date']):\n",
    "    # initialize sum dict\n",
    "    sums = {lbl: 0.0 for lbl in label_pool}\n",
    "    for lst in grp['m_ambience']:\n",
    "        for label, prob in lst:\n",
    "            sums[label] += float(prob)\n",
    "    row = {'subject_id': subj, 'date': day}\n",
    "    # 각 label별 확률 합계 추가\n",
    "    for lbl in label_pool:\n",
    "        row[f'{lbl}_prob_sum'] = sums[lbl]\n",
    "    rows.append(row)\n",
    "\n",
    "prep_mAmbience = pd.DataFrame(rows)\n",
    "print(prep_mAmbience.head())\n",
    "print(prep_mAmbience.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ec1850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id        date  total_usage_time_lev0_mean  \\\n",
      "0       id01  2024-06-26               142850.553034   \n",
      "1       id01  2024-06-27               111931.971924   \n",
      "2       id01  2024-06-28               109725.298833   \n",
      "3       id01  2024-06-29                96803.554352   \n",
      "4       id01  2024-06-30               152565.531960   \n",
      "\n",
      "   total_usage_time_lev0_std  total_usage_time_lev0_energy  \\\n",
      "0              320174.917383                  1.044805e+13   \n",
      "1              155658.006840                  6.542956e+12   \n",
      "2              141429.307699                  4.678116e+12   \n",
      "3              131253.540690                  3.351401e+12   \n",
      "4              204423.231830                  8.588593e+12   \n",
      "\n",
      "   total_usage_time_lev1_mean  total_usage_time_lev1_std  \\\n",
      "0                16868.787990              195746.453812   \n",
      "1               -10115.412519              225115.986414   \n",
      "2                -3088.248837              207698.429065   \n",
      "3                 7762.613261              182339.072653   \n",
      "4               -24755.793043              239793.620558   \n",
      "\n",
      "   total_usage_time_lev1_energy  total_usage_time_lev2_mean  \\\n",
      "0                  3.281105e+12                 8393.429136   \n",
      "1                  9.038756e+12                -4006.069624   \n",
      "2                  6.299634e+12                 -544.240020   \n",
      "3                  4.196782e+12                 2592.374962   \n",
      "4                  7.671026e+12                 6500.473761   \n",
      "\n",
      "   total_usage_time_lev2_std  ...  Wind noise (microphone)_prob_sum  \\\n",
      "0              180177.890292  ...                          0.100864   \n",
      "1              185136.200391  ...                          0.000000   \n",
      "2              181198.161862  ...                          0.116728   \n",
      "3              145464.131772  ...                          0.000000   \n",
      "4              212958.848610  ...                          0.000000   \n",
      "\n",
      "   Wood_prob_sum  Wood block_prob_sum  Writing_prob_sum  Yell_prob_sum  \\\n",
      "0       0.372201                  0.0          0.070800            0.0   \n",
      "1       0.000000                  0.0          0.000000            0.0   \n",
      "2       0.000000                  0.0          0.000000            0.0   \n",
      "3       0.000000                  0.0          0.035868            0.0   \n",
      "4       0.000000                  0.0          0.000000            0.0   \n",
      "\n",
      "   Yip_prob_sum  Yodeling_prob_sum  Zing_prob_sum  Zipper (clothing)_prob_sum  \\\n",
      "0           0.0                0.0            0.0                     0.01081   \n",
      "1           0.0                0.0            0.0                     0.00000   \n",
      "2           0.0                0.0            0.0                     0.00000   \n",
      "3           0.0                0.0            0.0                     0.00000   \n",
      "4           0.0                0.0            0.0                     0.00000   \n",
      "\n",
      "   Zither_prob_sum  \n",
      "0              0.0  \n",
      "1              0.0  \n",
      "2              0.0  \n",
      "3              0.0  \n",
      "4              0.0  \n",
      "\n",
      "[5 rows x 668 columns]\n",
      "(700, 668)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# assume daily_features is a dict of DataFrames for the 7 DWT‐processed tables:\n",
    "# daily_features = {\n",
    "#     'mUsageStats': dwt_mUsageStats,\n",
    "#     'wHr':          dwt_wHr,\n",
    "#     'mBle':         dwt_mBle,\n",
    "#     'mWifi':        dwt_mWifi,\n",
    "#     'wLight':       dwt_wLight,\n",
    "#     'mGps':         dwt_mGps,\n",
    "#     'wPedo':        dwt_wPedo,\n",
    "# }\n",
    "\n",
    "# and the two preprocessed frames:\n",
    "# prep_mActivity, prep_mAmbience\n",
    "\n",
    "# 1. collect all DataFrames in a list\n",
    "dfs = list(daily_features.values()) + [prep_mActivity, prep_mAmbience]\n",
    "\n",
    "# 2. merge them all on ['subject_id', 'date'] via outer join\n",
    "merged_df = reduce(\n",
    "    lambda left, right: pd.merge(\n",
    "        left, right,\n",
    "        on=['subject_id', 'date'],\n",
    "        how='outer'\n",
    "    ),\n",
    "    dfs\n",
    ")\n",
    "\n",
    "# 3. inspect\n",
    "print(merged_df.head())\n",
    "print(merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52abb2f",
   "metadata": {},
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d99c726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/ch2025_metrics_train.csv')\n",
    "test_df = pd.read_csv('../data/ch2025_submission_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d866e0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((450, 9), (250, 9))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c7055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wonjun_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
