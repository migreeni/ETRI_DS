{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5978bd",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60758fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecccdaf",
   "metadata": {},
   "source": [
    "## Variables to dataframe\n",
    "- df_{file}\n",
    "- df_{prep_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d22b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mACStatus\n",
      "df_mACStatus: (939896, 3)\n",
      "mScreenStatus\n",
      "df_mScreenStatus: (939653, 3)\n",
      "mUsageStats\n",
      "df_mUsageStats: (45197, 3)\n",
      "mActivity\n",
      "df_mActivity: (961062, 3)\n",
      "mBle\n",
      "df_mBle: (21830, 3)\n",
      "mWifi\n",
      "df_mWifi: (76336, 3)\n"
     ]
    }
   ],
   "source": [
    "challenge2025_dataset_path = \"ETRI_lifelog_dataset/ch2025_data_items/\"\n",
    "\n",
    "file_names = [\n",
    "    \"mACStatus\",\n",
    "    \"mScreenStatus\",\n",
    "    \"mUsageStats\",\n",
    "    \"mActivity\",\n",
    "    \"mBle\",\n",
    "    \"mWifi\"\n",
    "]\n",
    "\n",
    "df_dict = {}\n",
    "for name in file_names:\n",
    "    file_path = os.path.join(challenge2025_dataset_path, f\"ch2025_{name}.parquet\")\n",
    "    df_dict[name] = pd.read_parquet(file_path)\n",
    "    print(name)\n",
    "    print(f\"df_{name}: {df_dict[name].shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993430cd",
   "metadata": {},
   "source": [
    "## Train + Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f373068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_total.shape: (700, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>sleep_date</th>\n",
       "      <th>lifelog_date</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  sleep_date lifelog_date  Q1  Q2  Q3  S1  S2  S3\n",
       "0       id01  2024-06-27   2024-06-26   0   0   0   0   0   1\n",
       "1       id01  2024-06-28   2024-06-27   0   0   0   0   1   1\n",
       "2       id01  2024-06-29   2024-06-28   1   0   0   1   1   1\n",
       "3       id01  2024-06-30   2024-06-29   1   0   1   2   0   0\n",
       "4       id01  2024-07-01   2024-06-30   0   1   1   1   1   1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('ETRI_lifelog_dataset/ch2025_metrics_train.csv')\n",
    "df_test = pd.read_csv('ETRI_lifelog_dataset/ch2025_submission_sample.csv')\n",
    "\n",
    "df_total = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "print(\"df_total.shape:\", df_total.shape)\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a8565",
   "metadata": {},
   "source": [
    "## df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb114a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subject_id           timestamp\n",
      "0            id01 2024-06-26 00:00:00\n",
      "1            id01 2024-06-26 00:10:00\n",
      "2            id01 2024-06-26 00:20:00\n",
      "3            id01 2024-06-26 00:30:00\n",
      "4            id01 2024-06-26 00:40:00\n",
      "...           ...                 ...\n",
      "122827       id10 2024-09-26 23:10:00\n",
      "122828       id10 2024-09-26 23:20:00\n",
      "122829       id10 2024-09-26 23:30:00\n",
      "122830       id10 2024-09-26 23:40:00\n",
      "122831       id10 2024-09-26 23:50:00\n",
      "\n",
      "[122832 rows x 2 columns]\n",
      "(122832, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# lifelog_date가 string이면 datetime으로 변환\n",
    "df_total['lifelog_date'] = pd.to_datetime(df_total['lifelog_date'])\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for sid, group in df_total.groupby('subject_id'):\n",
    "    # 각 id별 min/max lifelog_date\n",
    "    min_date = group['lifelog_date'].min()\n",
    "    max_date = group['lifelog_date'].max()\n",
    "    \n",
    "    # 10분 단위로 timestamp 생성\n",
    "    timestamps = pd.date_range(start=min_date, end=max_date + pd.Timedelta(days=1) - pd.Timedelta(minutes=10), freq='10min')\n",
    "    # 위 코드에서 max_date + 1일 - 10분 까지 하는 이유는 23:50:00 포함시키기 위해서 (끝나는 날짜 23:50까지 포함)\n",
    "\n",
    "    # DataFrame 생성\n",
    "    df_id = pd.DataFrame({\n",
    "        'subject_id': sid,\n",
    "        'timestamp': timestamps\n",
    "    })\n",
    "    result_list.append(df_id)\n",
    "\n",
    "# 모든 id에 대해 concat\n",
    "df_merge = pd.concat(result_list, ignore_index=True)\n",
    "\n",
    "print(df_merge)\n",
    "print(df_merge.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85423456",
   "metadata": {},
   "source": [
    "### df_prep_mUsageStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed4771e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'app_name': '통화', 'total_time': 26419},\n",
       "       {'app_name': '토스', 'total_time': 119896},\n",
       "       {'app_name': '전화', 'total_time': 59284},\n",
       "       {'app_name': '카카오톡', 'total_time': 6744},\n",
       "       {'app_name': 'NAVER', 'total_time': 67042},\n",
       "       {'app_name': '\\xa0✝️성경일독Q', 'total_time': 1504},\n",
       "       {'app_name': 'One UI 홈', 'total_time': 209417}], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mUsageStats['m_usage_stats'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a84edbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  m_usage_time\n",
      "0       id01 2024-06-26 13:00:00          7955\n",
      "1       id01 2024-06-26 13:10:00        490306\n",
      "2       id01 2024-06-26 13:20:00        599985\n"
     ]
    }
   ],
   "source": [
    "# 'subject_id', 'timestamp' 열만 추출\n",
    "df_prep_mUsageStats = df_mUsageStats[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# 각 행에 대해 total_time의 합을 구하는 함수\n",
    "def sum_usage_time(usage_stats):\n",
    "    #usage_stats: list of dict\n",
    "    sum_time = 0\n",
    "    for usage in usage_stats:\n",
    "        # 'usage_time'이 없으면 0으로 처리\n",
    "        sum_time += usage.get('total_time', 0)\n",
    "    return sum_time\n",
    "\n",
    "df_prep_mUsageStats['m_usage_time'] = df_mUsageStats['m_usage_stats'].apply(sum_usage_time)\n",
    "\n",
    "# 결과 출력 (앞 10개)\n",
    "print(df_prep_mUsageStats.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcca1b3",
   "metadata": {},
   "source": [
    "### df_prep_mActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "089c1cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subject_id           timestamp  met_activity\n",
      "961052       id10 2024-09-26 23:50:00           1.1\n",
      "961053       id10 2024-09-26 23:51:00           1.1\n",
      "961054       id10 2024-09-26 23:52:00           1.1\n",
      "961055       id10 2024-09-26 23:53:00           1.1\n",
      "961056       id10 2024-09-26 23:54:00           1.1\n",
      "961057       id10 2024-09-26 23:55:00           1.1\n",
      "961058       id10 2024-09-26 23:56:00           1.1\n",
      "961059       id10 2024-09-26 23:57:00           1.1\n",
      "961060       id10 2024-09-26 23:58:00           1.1\n",
      "961061       id10 2024-09-26 23:59:00           1.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 'subject_id', 'timestamp'만 추출\n",
    "df_prep_mActivity = df_mActivity[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# 2. met_activity 열 선언\n",
    "df_prep_mActivity['met_activity'] = 0.0\n",
    "\n",
    "# 3. 매핑 함수와 시간대별 가중치 함수 정의\n",
    "activity_to_met = {0: 1.3, 1: 7.2, 2: 2.3, 3: 1.1, 4: 1.0, 5: 1.3, 7: 3.4, 8: 8.0}\n",
    "\n",
    "def get_time_weight(ts):\n",
    "    hour = ts.hour\n",
    "    if 0 <= hour < 8:\n",
    "        return 0.3\n",
    "    elif 8 <= hour < 18:\n",
    "        return 0.7\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "# timestamp를 datetime으로 변환\n",
    "df_prep_mActivity['timestamp'] = pd.to_datetime(df_prep_mActivity['timestamp'])\n",
    "\n",
    "# 4. 계산하여 met_activity 값 입력\n",
    "def calc_weighted_met(row):\n",
    "    met = activity_to_met.get(df_mActivity.loc[row.name, 'm_activity'], 1.0)  # 매핑 없으면 1.0\n",
    "    weight = get_time_weight(row['timestamp'])\n",
    "    return met * weight\n",
    "\n",
    "df_prep_mActivity['met_activity'] = df_prep_mActivity.apply(calc_weighted_met, axis=1)\n",
    "\n",
    "# 결과 확인 (head 10)\n",
    "print(df_prep_mActivity.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8349ae",
   "metadata": {},
   "source": [
    "### df_prep_mBle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d543abdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'address': '04:F5:AE:39:95:E0', 'device_class': '0', 'rssi': -44},\n",
       "       {'address': '0D:BE:52:E6:13:00', 'device_class': '0', 'rssi': -80},\n",
       "       {'address': '0F:13:09:75:36:FE', 'device_class': '0', 'rssi': -76},\n",
       "       {'address': '15:61:31:49:2F:F5', 'device_class': '0', 'rssi': -90},\n",
       "       {'address': '2B:70:D0:E0:3C:84', 'device_class': '0', 'rssi': -83},\n",
       "       {'address': '2F:EF:C3:70:A0:97', 'device_class': '0', 'rssi': -41},\n",
       "       {'address': '30:EF:FE:9E:E4:AD', 'device_class': '0', 'rssi': -70},\n",
       "       {'address': '38:54:47:EA:74:E1', 'device_class': '0', 'rssi': -61},\n",
       "       {'address': '38:C8:8D:5C:AD:83', 'device_class': '0', 'rssi': -71},\n",
       "       {'address': '40:BC:AF:DD:04:C5', 'device_class': '0', 'rssi': -92},\n",
       "       {'address': '45:33:4C:24:C4:C9', 'device_class': '0', 'rssi': -83},\n",
       "       {'address': '47:F1:F3:8D:95:20', 'device_class': '0', 'rssi': -88},\n",
       "       {'address': '54:15:89:95:27:44', 'device_class': '1064', 'rssi': -75},\n",
       "       {'address': '54:99:26:51:12:F3', 'device_class': '0', 'rssi': -94},\n",
       "       {'address': '68:78:B2:68:1E:A8', 'device_class': '0', 'rssi': -90},\n",
       "       {'address': '6B:62:EE:BC:2F:99', 'device_class': '0', 'rssi': -91},\n",
       "       {'address': '6C:4E:72:70:6F:EE', 'device_class': '0', 'rssi': -89},\n",
       "       {'address': '70:74:B0:C2:21:ED', 'device_class': '0', 'rssi': -78},\n",
       "       {'address': '77:8C:D6:D3:3F:BF', 'device_class': '0', 'rssi': -67},\n",
       "       {'address': 'C4:97:32:92:A1:26', 'device_class': '7936', 'rssi': -84},\n",
       "       {'address': 'DE:F8:26:CE:D2:D8', 'device_class': '0', 'rssi': -88},\n",
       "       {'address': 'E5:B9:2D:AA:DF:30', 'device_class': '0', 'rssi': -88}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mBle['m_ble'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  m_wtb_rssi\n",
      "0       id01 2024-06-26 12:13:00    0.102155\n",
      "1       id01 2024-06-26 12:23:00    0.098621\n",
      "2       id01 2024-06-26 12:33:00    0.037712\n",
      "(21830, 3)\n"
     ]
    }
   ],
   "source": [
    "# 'subject_id', 'timestamp' 열만 추출\n",
    "df_prep_mBle = df_mBle[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# 각 행에 대해 total_time의 합을 구하는 함수\n",
    "def sum_ble_rssi(ble_stats):\n",
    "    #ble_stats: list of dict\n",
    "    sum_rssi = 0\n",
    "    for ble in ble_stats:\n",
    "        # 'ble'이 없으면 0으로 처리\n",
    "        sum_rssi += np.exp(ble.get('rssi', 0) / 10)\n",
    "    return sum_rssi\n",
    "\n",
    "df_prep_mBle['m_wtb_rssi'] = df_mBle['m_ble'].apply(sum_ble_rssi)\n",
    "\n",
    "# 결과 출력 (앞 10개)\n",
    "print(df_prep_mBle.head(3))\n",
    "print(df_prep_mBle.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78c533b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  m_wtw_rssi\n",
      "0       id01 2024-06-26 12:03:00    0.202476\n",
      "1       id01 2024-06-26 12:13:00    0.091135\n",
      "2       id01 2024-06-26 12:23:00    0.063361\n",
      "(76336, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 'subject_id', 'timestamp' 열만 추출\n",
    "df_prep_mWifi = df_mWifi[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# 각 행에 대해 total_time의 합을 구하는 함수\n",
    "def sum_wifi_rssi(wifi_stats):\n",
    "    # wifi_stats: list of dict\n",
    "    sum_rssi = 0\n",
    "    for wifi in wifi_stats:\n",
    "        # 'rssi'가 없으면 0으로 처리\n",
    "        sum_rssi += np.exp(wifi.get('rssi', 0) / 10)\n",
    "    return sum_rssi\n",
    "\n",
    "df_prep_mWifi['m_wtw_rssi'] = df_mWifi['m_wifi'].apply(sum_wifi_rssi)\n",
    "\n",
    "# 결과 출력 (앞 10개)\n",
    "print(df_prep_mWifi.head(3))\n",
    "print(df_prep_mWifi.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
