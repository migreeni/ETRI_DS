{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "861d4228",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7538586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7f68d",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "- 각 데이터프레임 변수의 이름은 파일 이름을 그대로 사용함.  \n",
    "  예: `mBle.parquet` 파일 → 변수 이름 `mBle`\n",
    "- 전처리하는 데이터프레임의 이름은 'pre_'로 시작함. </br>\n",
    "  예: `mBle` → `pre_mBle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893f1bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mACStatus with shape (939896, 3)\n",
      "Loaded mScreenStatus with shape (939653, 3)\n",
      "Loaded mUsageStats with shape (45197, 3)\n",
      "Loaded mActivity with shape (961062, 3)\n",
      "Loaded mBle with shape (21830, 3)\n",
      "Loaded mWifi with shape (76336, 3)\n",
      "Loaded wHr with shape (382918, 3)\n",
      "Loaded wPedo with shape (748100, 9)\n",
      "Loaded mGps with shape (800611, 3)\n",
      "Loaded mLight with shape (96258, 3)\n",
      "Loaded wLight with shape (633741, 3)\n",
      "Loaded mAmbience with shape (476577, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path for data folder\n",
    "DATA_DIR = \"../data/\"\n",
    "\n",
    "# Main data item list\n",
    "file_names = [\n",
    "    \"mACStatus\", \"mScreenStatus\", \"mUsageStats\", \"mActivity\", \"mBle\", \"mWifi\",\n",
    "    \"wHr\", \"wPedo\", \"mGps\", \"mLight\",\"wLight\", \"mAmbience\"\n",
    "]\n",
    "\n",
    "data_files = {name: os.path.join(DATA_DIR, f\"ch2025_{name}.parquet\") for name in file_names}\n",
    "\n",
    "dfs = {}\n",
    "for name, file_path in data_files.items():\n",
    "    dfs[name] = pd.read_parquet(file_path)\n",
    "    globals()[name] = dfs[name]\n",
    "    print(f\"Loaded {name} with shape {dfs[name].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d87eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mACStatus DataFrame:\n",
      "  subject_id           timestamp  m_charging\n",
      "0       id01 2024-06-26 12:03:00           0\n",
      "1       id01 2024-06-26 12:04:00           0\n",
      "2       id01 2024-06-26 12:05:00           0\n",
      "3       id01 2024-06-26 12:06:00           0\n",
      "4       id01 2024-06-26 12:07:00           0\n"
     ]
    }
   ],
   "source": [
    "# Check one of the dataframes\n",
    "print(f\"mACStatus DataFrame:\\n{mACStatus.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2ba09",
   "metadata": {},
   "source": [
    "## Load training and test set\n",
    "\n",
    "- Training set dataframe: `train_df`\n",
    "- Test set dataframe: `test_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d865e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_df.shape: (700, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>sleep_date</th>\n",
       "      <th>lifelog_date</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  sleep_date lifelog_date  Q1  Q2  Q3  S1  S2  S3\n",
       "0       id01  2024-06-27   2024-06-26   0   0   0   0   0   1\n",
       "1       id01  2024-06-28   2024-06-27   0   0   0   0   1   1\n",
       "2       id01  2024-06-29   2024-06-28   1   0   0   1   1   1\n",
       "3       id01  2024-06-30   2024-06-29   1   0   1   2   0   0\n",
       "4       id01  2024-07-01   2024-06-30   0   1   1   1   1   1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train and test set\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"ch2025_metrics_train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"ch2025_submission_sample.csv\"))\n",
    "\n",
    "# Combine train and test\n",
    "total_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "print(\"total_df.shape:\", total_df.shape)\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5eb7d6",
   "metadata": {},
   "source": [
    "# 1. mACStatus\n",
    "- 스마트폰 충전 여부 (0: no, 1: charging)\n",
    "- 1분 단위\n",
    "---\n",
    "- **데이터에서 아웃 (temporal)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b45901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mACStatus DataFrame:\n",
      "   subject_id           timestamp  m_charging\n",
      "0       id01 2024-06-26 12:03:00           0\n",
      "1       id01 2024-06-26 12:04:00           0\n",
      "2       id01 2024-06-26 12:05:00           0\n"
     ]
    }
   ],
   "source": [
    "print(\"mACStatus DataFrame:\\n\", mACStatus.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911ec42",
   "metadata": {},
   "source": [
    "# 2. mScreenStatus\n",
    "- 스마트폰 스크린 사용 여부 (0: no, 1: using)\n",
    "- 1분 단위\n",
    "---\n",
    "- **데이터에서 아웃 → mUsageStats에 흡수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5768b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mScreenStatus DataFrame:\n",
      "   subject_id           timestamp  m_screen_use\n",
      "0       id01 2024-06-26 12:03:00             0\n",
      "1       id01 2024-06-26 12:04:00             0\n",
      "2       id01 2024-06-26 12:05:00             0\n"
     ]
    }
   ],
   "source": [
    "print(\"mScreenStatus DataFrame:\\n\", mScreenStatus.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd83611",
   "metadata": {},
   "source": [
    "# 3. mUsageStats\n",
    "- timestamp 당 사용한 app과 사용시간(ms단위)\n",
    "- 10분 단위(불규칙적)\n",
    "---\n",
    "- m_usage_stats 중 사용시간만 합쳐서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2335a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mUsageStats DataFrame:\n",
      "   subject_id           timestamp  \\\n",
      "0       id01 2024-06-26 13:00:00   \n",
      "1       id01 2024-06-26 13:10:00   \n",
      "2       id01 2024-06-26 13:20:00   \n",
      "\n",
      "                                       m_usage_stats  \n",
      "0  [{'app_name': ' 캐시워크', 'total_time': 69}, {'ap...  \n",
      "1  [{'app_name': '통화', 'total_time': 26419}, {'ap...  \n",
      "2  [{'app_name': '메시지', 'total_time': 388651}, {'...  \n"
     ]
    }
   ],
   "source": [
    "print(\"mUsageStats DataFrame:\\n\", mUsageStats.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89a101c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only subject_id and timestamp columns\n",
    "prep_mUsageStats = mUsageStats[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# Calculate sum of 'total_time' for each row\n",
    "def sum_usage_time(usage_stats):\n",
    "    return sum(usage.get('total_time', 0) for usage in usage_stats)\n",
    "\n",
    "prep_mUsageStats['m_usage_time'] = mUsageStats['m_usage_stats'].apply(sum_usage_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8dd2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  m_usage_time\n",
      "0       id01 2024-06-26 13:00:00          7955\n",
      "1       id01 2024-06-26 13:10:00        490306\n",
      "2       id01 2024-06-26 13:20:00        599985\n",
      "3       id01 2024-06-26 13:30:00        212438\n",
      "4       id01 2024-06-26 13:50:00        118178\n"
     ]
    }
   ],
   "source": [
    "print(prep_mUsageStats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af68db4",
   "metadata": {},
   "source": [
    "# 4. mActivity\n",
    "\n",
    "- 각 timestamp별로 어떤 활동(m_activity)을 했는지\n",
    "---\n",
    "- 새로운 변수 met_activity 생성\n",
    "    - m_activity에 MET(운동량 지수)를 매핑\n",
    "    - 시간대 (00~08 / 08~18 / 18~00) 별로 weight 을 달리 주어(0.3 / 0.7 / 1.0) 저녁일수록 더 영향을 주는 활동임을 반영\n",
    "- met_activity 변수만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34a2f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mActivity DataFrame:\n",
      "   subject_id           timestamp  m_activity\n",
      "0       id01 2024-06-26 12:03:00           4\n",
      "1       id01 2024-06-26 12:04:00           0\n",
      "2       id01 2024-06-26 12:05:00           0\n"
     ]
    }
   ],
   "source": [
    "print(\"mActivity DataFrame:\\n\", mActivity.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9177bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy required columns from mActivity\n",
    "prep_mActivity = mActivity[['subject_id', 'timestamp', 'm_activity']].copy()\n",
    "\n",
    "# MET values for each activity type\n",
    "activity_to_met = {0: 1.3, 1: 7.2, 2: 2.3, 3: 1.1, 4: 1.0, 5: 1.3, 7: 3.4, 8: 8.0}\n",
    "\n",
    "# Function for time-based weight\n",
    "def get_time_weight(ts):\n",
    "    hour = ts.hour\n",
    "    if 0 <= hour < 8:\n",
    "        return 0.3\n",
    "    elif 8 <= hour < 18:\n",
    "        return 0.7\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "# Convert 'timestamp' to datetime\n",
    "prep_mActivity['timestamp'] = pd.to_datetime(prep_mActivity['timestamp'])\n",
    "\n",
    "# Calculate weighted MET value for each row\n",
    "prep_mActivity['met_activity'] = prep_mActivity.apply(\n",
    "    lambda row: activity_to_met.get(row['m_activity'], 1.0) * get_time_weight(row['timestamp']), axis=1\n",
    ")\n",
    "\n",
    "# Keep only final columns\n",
    "prep_mActivity = prep_mActivity[['subject_id', 'timestamp', 'met_activity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18fc7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  met_activity\n",
      "0       id01 2024-06-26 12:03:00          0.70\n",
      "1       id01 2024-06-26 12:04:00          0.91\n",
      "2       id01 2024-06-26 12:05:00          0.91\n",
      "3       id01 2024-06-26 12:06:00          0.91\n",
      "4       id01 2024-06-26 12:07:00          0.91\n",
      "5       id01 2024-06-26 12:08:00          0.91\n",
      "6       id01 2024-06-26 12:09:00          0.91\n",
      "7       id01 2024-06-26 12:10:00          0.91\n",
      "8       id01 2024-06-26 12:11:00          0.77\n",
      "9       id01 2024-06-26 12:12:00          0.77\n"
     ]
    }
   ],
   "source": [
    "print(prep_mActivity.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec8c184",
   "metadata": {},
   "source": [
    "# 5. mBle\n",
    "- timestampe당 주변 Bluetooth 기기들의 address, device class, rssi 값 저장\n",
    "- address : 블루투스 기기의 고유식별자 (MAC address)\n",
    "- device_class : 블루투스 기기의 class(분류)\n",
    "- rssi : 신호 세기, 기기로부터 수신된 신호의 강도 (0에 가까운 값을수록 신호 강함)\n",
    "--- \n",
    "- 기기가 가까이 있으면 전자파로 수면에 방해를 줄 수 있으므로, rssi 값만 고려하여 변수를 생성\n",
    "- 변수 이름 wb_rssi (weighted bluetooth rssi)\n",
    "- weighted rssi 생성 방법\n",
    "    - 각 timestamp에 대해 다음과 같이 계산\n",
    "    $$\n",
    "    \\text{weighted rssi} = \\sum e^{\\frac{\\text{rssi}}{10}}\n",
    "    $$\n",
    "- 다른 방식으로 변수를 만들 수도 있음\n",
    "    - 예: 기준에 따라 범주(label) 나누고 → sigmoid function 으로 변환 (주형)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de56317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mBle DataFrame:\n",
      "   subject_id           timestamp  \\\n",
      "0       id01 2024-06-26 12:13:00   \n",
      "1       id01 2024-06-26 12:23:00   \n",
      "2       id01 2024-06-26 12:33:00   \n",
      "\n",
      "                                               m_ble  \n",
      "0  [{'address': '00:15:7C:11:80:8D', 'device_clas...  \n",
      "1  [{'address': '0A:B1:26:4D:76:21', 'device_clas...  \n",
      "2  [{'address': '04:F5:AE:39:95:E0', 'device_clas...  \n"
     ]
    }
   ],
   "source": [
    "print(\"mBle DataFrame:\\n\", mBle.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8846c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'subject_id' and 'timestamp' columns\n",
    "prep_mBle = mBle[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# Calculate weighted bluetooth RSSI for each row\n",
    "def weighted_ble_rssi(ble_stats):\n",
    "    return sum(np.exp(ble.get('rssi', 0) / 10) for ble in ble_stats)\n",
    "\n",
    "prep_mBle['wb_rssi'] = mBle['m_ble'].apply(weighted_ble_rssi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56318a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp   wb_rssi\n",
      "0       id01 2024-06-26 12:13:00  0.102155\n",
      "1       id01 2024-06-26 12:23:00  0.098621\n",
      "2       id01 2024-06-26 12:33:00  0.037712\n"
     ]
    }
   ],
   "source": [
    "print(prep_mBle.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b865b",
   "metadata": {},
   "source": [
    "# 6. mWifi\n",
    "- timestampe당 주변 Wifi 기기들의 bssid, rssi 값 저장\n",
    "- bssid : 무선 액세스 포인트의 고유식별자 (MAC address)\n",
    "- rssi : 신호 세기, 기기로부터 수신된 신호의 강도 (0에 가까운 값을수록 신호 강함)\n",
    "--- \n",
    "mBle와 같은 방식으로,\n",
    "- 기기가 가까이 있으면 전자파로 수면에 방해를 줄 수 있으므로, rssi 값만 고려하여 변수를 생성\n",
    "- 변수 이름 ww_rssi (weighted wifi rssi)\n",
    "- weighted rssi 생성 방법\n",
    "    - 각 timestamp에 대해 다음과 같이 계산\n",
    "    $$\n",
    "    \\text{weighted rssi} = \\sum e^{\\frac{\\text{rssi}}{10}}\n",
    "    $$\n",
    "- 마찬가지로, 다른 방식으로 변수를 만들 수도 있음\n",
    "    - 예: 기준에 따라 범주(label) 나누고 → sigmoid function 으로 변환 (주형)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e6ffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mWifi DataFrame:\n",
      "   subject_id           timestamp  \\\n",
      "0       id01 2024-06-26 12:03:00   \n",
      "1       id01 2024-06-26 12:13:00   \n",
      "2       id01 2024-06-26 12:23:00   \n",
      "\n",
      "                                              m_wifi  \n",
      "0  [{'bssid': 'a0:0f:37:9a:5d:8b', 'rssi': -78}, ...  \n",
      "1  [{'bssid': 'a0:0f:37:9a:5d:8b', 'rssi': -79}, ...  \n",
      "2  [{'bssid': '10:e3:c7:0a:74:d1', 'rssi': -78}, ...  \n"
     ]
    }
   ],
   "source": [
    "print(\"mWifi DataFrame:\\n\", mWifi.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45cf8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'subject_id' and 'timestamp' columns\n",
    "prep_mWifi = mWifi[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# Calculate weighted wifi RSSI for each row\n",
    "def weighted_wifi_rssi(wifi_stats):\n",
    "    return sum(np.exp(wifi.get('rssi', 0) / 10) for wifi in wifi_stats)\n",
    "\n",
    "prep_mWifi['ww_rssi'] = mWifi['m_wifi'].apply(weighted_wifi_rssi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5c4ca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp   ww_rssi\n",
      "0       id01 2024-06-26 12:03:00  0.202476\n",
      "1       id01 2024-06-26 12:13:00  0.091135\n",
      "2       id01 2024-06-26 12:23:00  0.063361\n"
     ]
    }
   ],
   "source": [
    "print(prep_mWifi.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f25b97",
   "metadata": {},
   "source": [
    "# 7. wHr\n",
    "- timestamp 당 초당 heart_rate\n",
    "---\n",
    "- timestamp 당 평균 heart_rate를 avg_heart_rate 로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf0844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wHr DataFrame:\n",
      "   subject_id           timestamp  \\\n",
      "0       id01 2024-06-26 12:23:00   \n",
      "1       id01 2024-06-26 12:24:00   \n",
      "2       id01 2024-06-26 12:25:00   \n",
      "\n",
      "                                          heart_rate  \n",
      "0  [134, 134, 135, 133, 134, 135, 134, 135, 134, ...  \n",
      "1  [123, 122, 121, 120, 121, 121, 120, 118, 119, ...  \n",
      "2  [120, 119, 117, 116, 119, 121, 123, 123, 121, ...  \n"
     ]
    }
   ],
   "source": [
    "print(\"wHr DataFrame:\\n\", wHr.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ebcd0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_wHr = wHr[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# Calculate average heart rate for each row and store in 'avg_heart_rate'\n",
    "prep_wHr['avg_heart_rate'] = wHr['heart_rate'].apply(lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "804c4a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  avg_heart_rate\n",
      "0       id01 2024-06-26 12:23:00      130.794872\n",
      "1       id01 2024-06-26 12:24:00      120.500000\n",
      "2       id01 2024-06-26 12:25:00      119.850000\n"
     ]
    }
   ],
   "source": [
    "print(prep_wHr.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced49beb",
   "metadata": {},
   "source": [
    "# 8. wPedo\n",
    "- Step count data and related information measured by the smartwatch.\n",
    "- burned calories, distance, speed, steps, step_frequency\n",
    "---\n",
    "- running_step, walking_step, step, step_frequency drop (Why?)\n",
    "- distance, burned calories 만 살림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e03dd128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wPedo DataFrame:\n",
      "   subject_id           timestamp  step  step_frequency  running_step  \\\n",
      "0       id01 2024-06-26 12:09:00    10        0.166667             0   \n",
      "1       id01 2024-06-26 12:10:00     0        0.000000             0   \n",
      "2       id01 2024-06-26 12:11:00     0        0.000000             0   \n",
      "\n",
      "   walking_step  distance     speed  burned_calories  \n",
      "0             0      8.33  0.138833              0.0  \n",
      "1             0      0.00  0.000000              0.0  \n",
      "2             0      0.00  0.000000              0.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"wPedo DataFrame:\\n\", wPedo.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db036b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_wPedo = wPedo[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# Keep only subject_id, timestamp, distance, and burned_calories\n",
    "prep_wPedo = wPedo[['subject_id', 'timestamp', 'distance', 'burned_calories']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbae590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  distance  burned_calories\n",
      "0       id01 2024-06-26 12:09:00      8.33              0.0\n",
      "1       id01 2024-06-26 12:10:00      0.00              0.0\n",
      "2       id01 2024-06-26 12:11:00      0.00              0.0\n"
     ]
    }
   ],
   "source": [
    "print(prep_wPedo.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf319ead",
   "metadata": {},
   "source": [
    "# 9. mGps\n",
    "- m_gps\n",
    "    - atitude, longitude, altitude, speed\n",
    "- 12 times per minute\n",
    "- latitude and longitude converted to relative coordinates for privacy protection\n",
    "---\n",
    "- 각 timestamp 당 latitude, longitude, altitude, speed 평균값을 추가.\n",
    "- 변수 이름은 avg_latitude, avg_longitude, avg_altitude, avg_speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "859b35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mGps DataFrame:\n",
      "   subject_id           timestamp  \\\n",
      "0       id01 2024-06-26 12:03:00   \n",
      "1       id01 2024-06-26 12:04:00   \n",
      "2       id01 2024-06-26 12:05:00   \n",
      "\n",
      "                                               m_gps  \n",
      "0  [{'altitude': 110.6, 'latitude': 0.2077385, 'l...  \n",
      "1  [{'altitude': 110.8, 'latitude': 0.2078068, 'l...  \n",
      "2  [{'altitude': 110.7, 'latitude': 0.2078214, 'l...  \n"
     ]
    }
   ],
   "source": [
    "print(\"mGps DataFrame:\\n\", mGps.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "364f8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract needed columns\n",
    "prep_mGps = mGps[['subject_id', 'timestamp']].copy()\n",
    "\n",
    "# Function to calculate averages for each list of gps dicts\n",
    "def calc_gps_avgs(gps_list, key):\n",
    "    vals = [item.get(key, np.nan) for item in gps_list if item.get(key) is not None]\n",
    "    return np.mean(vals) if vals else np.nan\n",
    "\n",
    "prep_mGps['avg_latitude'] = mGps['m_gps'].apply(lambda gps: calc_gps_avgs(gps, 'latitude'))\n",
    "prep_mGps['avg_longitude'] = mGps['m_gps'].apply(lambda gps: calc_gps_avgs(gps, 'longitude'))\n",
    "prep_mGps['avg_altitude'] = mGps['m_gps'].apply(lambda gps: calc_gps_avgs(gps, 'altitude'))\n",
    "prep_mGps['avg_speed'] = mGps['m_gps'].apply(lambda gps: calc_gps_avgs(gps, 'speed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85c68bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  avg_latitude  avg_longitude  avg_altitude  \\\n",
      "0       id01 2024-06-26 12:03:00      0.207788       0.169974    110.763636   \n",
      "1       id01 2024-06-26 12:04:00      0.207812       0.169962    110.718182   \n",
      "2       id01 2024-06-26 12:05:00      0.207829       0.169959    110.709091   \n",
      "\n",
      "   avg_speed  \n",
      "0   0.170755  \n",
      "1   0.028209  \n",
      "2   0.039736  \n"
     ]
    }
   ],
   "source": [
    "print(prep_mGps.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec380703",
   "metadata": {},
   "source": [
    "# 10. wLight & 11. mLight\n",
    "- 10분 단위\n",
    "- m_light : Ambient light in lx unit\n",
    "- w_light : Ambient light in lx unit\n",
    "--- \n",
    "- 둘 중에 결측이 적은 wLight 사용\n",
    "- 따로 전처리 필요 없음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5584a032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mLight DataFrame:\n",
      "   subject_id           timestamp  m_light\n",
      "0       id01 2024-06-26 12:03:00    534.0\n",
      "1       id01 2024-06-26 12:13:00    846.0\n",
      "2       id01 2024-06-26 12:23:00    826.0\n",
      "\n",
      "\n",
      "wLight DataFrame:\n",
      "   subject_id           timestamp  w_light\n",
      "0       id01 2024-06-26 12:17:00    633.0\n",
      "1       id01 2024-06-26 12:18:00    483.0\n",
      "2       id01 2024-06-26 12:19:00    541.0\n"
     ]
    }
   ],
   "source": [
    "print(\"mLight DataFrame:\\n\", mLight.head(3))\n",
    "print(\"\\n\")\n",
    "print(\"wLight DataFrame:\\n\", wLight.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b5c4c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_wLight = wLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cf3d429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  w_light\n",
      "0       id01 2024-06-26 12:17:00    633.0\n",
      "1       id01 2024-06-26 12:18:00    483.0\n",
      "2       id01 2024-06-26 12:19:00    541.0\n"
     ]
    }
   ],
   "source": [
    "print(prep_wLight.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65fbcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa959d7d",
   "metadata": {},
   "source": [
    "# 12. mAbience\n",
    "- Audio-based labels detected on smartphones. Recorded once every 2 minutes.\n",
    "- ambience_labels: List of the top 10 labels along with their respective probabilities.\n",
    "---\n",
    "- 일단은 baseline 대로 바꿈\n",
    "    - top_10_label에 있는 항목들이 row의 m_ambience에 존재할 경우\n",
    "    - probability 를 모두 더해서 prob_ambience 값을 저장\n",
    "- (건호)님이 하신 거로 나중에 바꾸면 될 거 같습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8628bab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAmbience DataFrame:\n",
      "   subject_id           timestamp  \\\n",
      "0       id01 2024-06-26 13:00:10   \n",
      "1       id01 2024-06-26 13:02:10   \n",
      "2       id01 2024-06-26 13:04:10   \n",
      "\n",
      "                                          m_ambience  \n",
      "0  [[Music, 0.30902618], [Vehicle, 0.081680894], ...  \n",
      "1  [[Music, 0.62307084], [Vehicle, 0.021118319], ...  \n",
      "2  [[Horse, 0.25209898], [Animal, 0.24263993], [C...  \n"
     ]
    }
   ],
   "source": [
    "print(\"mAmbience DataFrame:\\n\", mAmbience.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b71de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of top 10 labels\n",
    "top_10_labels = [\n",
    "    \"Inside, small room\", \"Speech\", \"Silence\", \"Music\",\n",
    "    \"Narration, monologue\", \"Child speech, kid speaking\",\n",
    "    \"Conversation\", \"Speech synthesizer\", \"Shout\", \"Babbling\"\n",
    "]\n",
    "\n",
    "def calc_prob_ambience(amb_list):\n",
    "    # Check if amb_list is None or has zero length\n",
    "    if amb_list is None or len(amb_list) == 0:\n",
    "        return 0.0\n",
    "    prob_sum = 0.0\n",
    "    for arr in amb_list:\n",
    "        if isinstance(arr, (list, np.ndarray)) and len(arr) == 2:\n",
    "            label = arr[0]\n",
    "            try:\n",
    "                prob = float(arr[1])\n",
    "            except:\n",
    "                prob = 0.0\n",
    "            if label in top_10_labels:\n",
    "                prob_sum += prob\n",
    "    return prob_sum\n",
    "\n",
    "prep_mAmbience = mAmbience[['subject_id', 'timestamp']].copy()\n",
    "prep_mAmbience['prob_ambience'] = mAmbience['m_ambience'].apply(calc_prob_ambience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "286bad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id           timestamp  prob_ambience\n",
      "0       id01 2024-06-26 13:00:10       0.338832\n",
      "1       id01 2024-06-26 13:02:10       0.623071\n",
      "2       id01 2024-06-26 13:04:10       0.000000\n"
     ]
    }
   ],
   "source": [
    "print(prep_mAmbience.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede9a8c",
   "metadata": {},
   "source": [
    "# Merge!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988b561",
   "metadata": {},
   "source": [
    "### Generate df_merge\n",
    "- 각 전처리 데이터마다, subject_id별로 가장 이른 timestamp(min)와 가장 늦은 timestamp(max)을 찾음\n",
    "- 각 파일에서 추출한 min/max timestamp 중 가장 이른 시간을 min_time, 가장 늦은 시간을 max_time으로 설정\n",
    "    - min_time과 max_time이 10분 단위가 아닐 경우, min_time은 내림(가장 가까운 이전 10분), max_time은 올림(가장 가까운 이후 10분)으로 변환\n",
    "- 각 subject_id별로 모든 전처리 데이터에서의 최소~최대 timestamp 구간을 10분 단위로 생성하여, 전체 subject의 타임라인을 merge_df로 통합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a59f4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all preprocessed DataFrame variable names (already loaded in the session)\n",
    "preprocessed_files = [\n",
    "    prep_mActivity,prep_mUsageStats, prep_mAmbience,\n",
    "    prep_mBle, prep_mGps,prep_mWifi, prep_wHr, prep_wLight, prep_wPedo\n",
    "]\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# Get all unique subject_ids (assume every file has subject_id column)\n",
    "all_ids = sorted(set(np.concatenate([df['subject_id'].unique() for df in preprocessed_files])))\n",
    "\n",
    "for sid in all_ids:\n",
    "    min_times, max_times = [], []\n",
    "    # Find min/max timestamp per file for the current subject_id\n",
    "    for df in preprocessed_files:\n",
    "        df_id = df[df['subject_id'] == sid]\n",
    "        if len(df_id) > 0:\n",
    "            min_times.append(df_id['timestamp'].min())\n",
    "            max_times.append(df_id['timestamp'].max())\n",
    "    # Combine all min/max times\n",
    "    if len(min_times) == 0 or len(max_times) == 0:\n",
    "        continue  # No data for this id in any file\n",
    "\n",
    "    # Get global min_time and max_time across all files (as pd.Timestamp)\n",
    "    min_time = pd.to_datetime(min(min_times))\n",
    "    max_time = pd.to_datetime(max(max_times))\n",
    "\n",
    "    # Floor min_time to nearest 10min, Ceil max_time to nearest 10min\n",
    "    def floor_10min(ts):\n",
    "        return ts - pd.Timedelta(minutes=ts.minute % 10, seconds=ts.second, microseconds=ts.microsecond)\n",
    "    def ceil_10min(ts):\n",
    "        if ts.minute % 10 == 0 and ts.second == 0 and ts.microsecond == 0:\n",
    "            return ts\n",
    "        return ts + pd.Timedelta(minutes=10 - ts.minute % 10, seconds=-ts.second, microseconds=-ts.microsecond)\n",
    "\n",
    "    min_time_10 = floor_10min(min_time)\n",
    "    max_time_10 = ceil_10min(max_time)\n",
    "\n",
    "    # Create timestamp range for this subject_id\n",
    "    timestamps = pd.date_range(start=min_time_10, end=max_time_10, freq='10min')\n",
    "\n",
    "    # Create DataFrame for this subject_id\n",
    "    df_id = pd.DataFrame({'subject_id': sid, 'timestamp': timestamps})\n",
    "    result_list.append(df_id)\n",
    "\n",
    "# Concatenate all results\n",
    "merge_df = pd.concat(result_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aedf330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge dataframe:\n",
      "        subject_id           timestamp\n",
      "0            id01 2024-06-26 12:00:00\n",
      "1            id01 2024-06-26 12:10:00\n",
      "2            id01 2024-06-26 12:20:00\n",
      "3            id01 2024-06-26 12:30:00\n",
      "4            id01 2024-06-26 12:40:00\n",
      "...           ...                 ...\n",
      "122276       id10 2024-09-26 23:20:00\n",
      "122277       id10 2024-09-26 23:30:00\n",
      "122278       id10 2024-09-26 23:40:00\n",
      "122279       id10 2024-09-26 23:50:00\n",
      "122280       id10 2024-09-27 00:00:00\n",
      "\n",
      "[122281 rows x 2 columns]\n",
      "merge_df shape\n",
      " (122281, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"merge dataframe:\\n\", merge_df)\n",
    "print(\"merge_df shape\\n\", merge_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4104fc1d",
   "metadata": {},
   "source": [
    "### Merging all preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38034935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prep_mUsageStats: assign m_usage_time by exact timestamp match\n",
    "merge_df = merge_df.sort_values(['subject_id', 'timestamp'])\n",
    "merge_df = merge_df.reset_index(drop=True)\n",
    "\n",
    "# Add columns\n",
    "merge_df['m_usage_time'] = np.nan\n",
    "merge_df['met_activity'] = 0.0\n",
    "merge_df['wb_rssi'] = np.nan\n",
    "merge_df['ww_rssi'] = np.nan\n",
    "\n",
    "sid = 'id01' # 원하는 subject_id로 지정\n",
    "\n",
    "# 1. prep_mUsageStats: exact match\n",
    "usage = prep_mUsageStats[prep_mUsageStats['subject_id'] == sid]\n",
    "usage = usage.set_index('timestamp')\n",
    "merge_mask = (merge_df['subject_id'] == sid)\n",
    "merge_df.loc[merge_mask, 'm_usage_time'] = merge_df[merge_mask]['timestamp'].map(usage['m_usage_time'])\n",
    "\n",
    "# 2. prep_mActivity: closest timestamp, sum if multiple\n",
    "activity = prep_mActivity[prep_mActivity['subject_id'] == sid]\n",
    "for _, row in activity.iterrows():\n",
    "    # Find closest timestamp in merge_df\n",
    "    idx = (merge_df[merge_mask]['timestamp'] - row['timestamp']).abs().idxmin()\n",
    "    # Sum met_activity if already exists\n",
    "    merge_df.loc[idx, 'met_activity'] += row['met_activity']\n",
    "\n",
    "# 3. prep_mBle: closest timestamp, assign\n",
    "ble = prep_mBle[prep_mBle['subject_id'] == sid]\n",
    "for _, row in ble.iterrows():\n",
    "    idx = (merge_df[merge_mask]['timestamp'] - row['timestamp']).abs().idxmin()\n",
    "    merge_df.loc[idx, 'wb_rssi'] = row['wb_rssi']\n",
    "\n",
    "# 4. prep_mWifi: closest timestamp, assign\n",
    "wifi = prep_mWifi[prep_mWifi['subject_id'] == sid]\n",
    "for _, row in wifi.iterrows():\n",
    "    idx = (merge_df[merge_mask]['timestamp'] - row['timestamp']).abs().idxmin()\n",
    "    merge_df.loc[idx, 'ww_rssi'] = row['ww_rssi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e231185c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subject_id           timestamp  m_usage_time  met_activity  wb_rssi  \\\n",
      "122271       id10 2024-09-26 22:30:00           NaN           0.0      NaN   \n",
      "122272       id10 2024-09-26 22:40:00           NaN           0.0      NaN   \n",
      "122273       id10 2024-09-26 22:50:00           NaN           0.0      NaN   \n",
      "122274       id10 2024-09-26 23:00:00           NaN           0.0      NaN   \n",
      "122275       id10 2024-09-26 23:10:00           NaN           0.0      NaN   \n",
      "122276       id10 2024-09-26 23:20:00           NaN           0.0      NaN   \n",
      "122277       id10 2024-09-26 23:30:00           NaN           0.0      NaN   \n",
      "122278       id10 2024-09-26 23:40:00           NaN           0.0      NaN   \n",
      "122279       id10 2024-09-26 23:50:00           NaN           0.0      NaN   \n",
      "122280       id10 2024-09-27 00:00:00           NaN           0.0      NaN   \n",
      "\n",
      "        ww_rssi  \n",
      "122271      NaN  \n",
      "122272      NaN  \n",
      "122273      NaN  \n",
      "122274      NaN  \n",
      "122275      NaN  \n",
      "122276      NaN  \n",
      "122277      NaN  \n",
      "122278      NaN  \n",
      "122279      NaN  \n",
      "122280      NaN  \n"
     ]
    }
   ],
   "source": [
    "#print(merge_df.head(10))\n",
    "print(merge_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d8d2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---- 1. wHr (avg_heart_rate, 평균) ----\n",
    "merge_df['sum_heart_rate'] = 0.0\n",
    "merge_df['count_heart_rate'] = 0\n",
    "merge_df['avg_heart_rate'] = np.nan\n",
    "\n",
    "wh = prep_wHr[prep_wHr['subject_id'] == sid]\n",
    "for _, row in wh.iterrows():\n",
    "    idx = (merge_df[merge_df['subject_id'] == sid]['timestamp'] - row['timestamp']).abs().idxmin()\n",
    "    merge_df.loc[idx, 'sum_heart_rate'] += row['avg_heart_rate']\n",
    "    merge_df.loc[idx, 'count_heart_rate'] += 1\n",
    "\n",
    "mask = merge_df['count_heart_rate'] > 0\n",
    "merge_df.loc[mask, 'avg_heart_rate'] = merge_df.loc[mask, 'sum_heart_rate'] / merge_df.loc[mask, 'count_heart_rate']\n",
    "merge_df = merge_df.drop(['sum_heart_rate', 'count_heart_rate'], axis=1)\n",
    "\n",
    "# ---- 2. wPedo (distance, burned_calories: 단순 합) ----\n",
    "merge_df['distance'] = 0.0\n",
    "merge_df['burned_calories'] = 0.0\n",
    "\n",
    "wp = prep_wPedo[prep_wPedo['subject_id'] == sid]\n",
    "for _, row in wp.iterrows():\n",
    "    idx = (merge_df[merge_df['subject_id'] == sid]['timestamp'] - row['timestamp']).abs().idxmin()\n",
    "    merge_df.loc[idx, 'distance'] += row['distance']\n",
    "    merge_df.loc[idx, 'burned_calories'] += row['burned_calories']\n",
    "\n",
    "# ---- 3. mGps (4개, 평균) ----\n",
    "for col in ['avg_latitude', 'avg_longitude', 'avg_altitude', 'avg_speed']:\n",
    "    merge_df['sum_' + col] = 0.0\n",
    "    merge_df['count_' + col] = 0\n",
    "    merge_df[col] = np.nan\n",
    "\n",
    "mgps = prep_mGps[prep_mGps['subject_id'] == sid]\n",
    "for _, row in mgps.iterrows():\n",
    "    idx = (merge_df[merge_df['subject_id'] == sid]['timestamp'] - row['timestamp']).abs().idxmin()\n",
    "    for col in ['avg_latitude', 'avg_longitude', 'avg_altitude', 'avg_speed']:\n",
    "        val = row[col]\n",
    "        merge_df.loc[idx, 'sum_' + col] += val\n",
    "        merge_df.loc[idx, 'count_' + col] += 1\n",
    "\n",
    "for col in ['avg_latitude', 'avg_longitude', 'avg_altitude', 'avg_speed']:\n",
    "    mask = merge_df['count_' + col] > 0\n",
    "    merge_df.loc[mask, col] = merge_df.loc[mask, 'sum_' + col] / merge_df.loc[mask, 'count_' + col]\n",
    "    merge_df.drop(['sum_' + col, 'count_' + col], axis=1, inplace=True)\n",
    "\n",
    "# ---- 4. wLight (평균) ----\n",
    "merge_df['sum_light'] = 0.0\n",
    "merge_df['count_light'] = 0\n",
    "merge_df['avg_light'] = np.nan\n",
    "\n",
    "wl = prep_wLight[prep_wLight['subject_id'] == sid]\n",
    "for _, row in wl.iterrows():\n",
    "    idx = (merge_df[merge_df['subject_id'] == sid]['timestamp'] - row['timestamp']).abs().idxmin()\n",
    "    merge_df.loc[idx, 'sum_light'] += row['w_light']\n",
    "    merge_df.loc[idx, 'count_light'] += 1\n",
    "\n",
    "mask = merge_df['count_light'] > 0\n",
    "merge_df.loc[mask, 'avg_light'] = merge_df.loc[mask, 'sum_light'] / merge_df.loc[mask, 'count_light']\n",
    "merge_df = merge_df.drop(['sum_light', 'count_light'], axis=1)\n",
    "\n",
    "# ---- 5. mAmbience (평균, 컬럼명은 avg_prob_ambience로 가정) ----\n",
    "merge_df['sum_prob_ambience'] = 0.0\n",
    "merge_df['count_prob_ambience'] = 0\n",
    "merge_df['avg_prob_ambience'] = np.nan\n",
    "\n",
    "amb = prep_mAmbience[prep_mAmbience['subject_id'] == sid]\n",
    "for _, row in amb.iterrows():\n",
    "    idx = (merge_df[merge_df['subject_id'] == sid]['timestamp'] - row['timestamp']).abs().idxmin()\n",
    "    merge_df.loc[idx, 'sum_prob_ambience'] += row['prob_ambience']\n",
    "    merge_df.loc[idx, 'count_prob_ambience'] += 1\n",
    "\n",
    "mask = merge_df['count_prob_ambience'] > 0\n",
    "merge_df.loc[mask, 'avg_prob_ambience'] = merge_df.loc[mask, 'sum_prob_ambience'] / merge_df.loc[mask, 'count_prob_ambience']\n",
    "merge_df = merge_df.drop(['sum_prob_ambience', 'count_prob_ambience'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28aaf381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id           timestamp  m_usage_time  met_activity   wb_rssi  \\\n",
      "0        id01 2024-06-26 12:00:00           NaN          2.52       NaN   \n",
      "1        id01 2024-06-26 12:10:00           NaN          8.40  0.102155   \n",
      "2        id01 2024-06-26 12:20:00           NaN          7.70  0.098621   \n",
      "3        id01 2024-06-26 12:30:00           NaN          7.70  0.037712   \n",
      "4        id01 2024-06-26 12:40:00           NaN         12.67       NaN   \n",
      "5        id01 2024-06-26 12:50:00           NaN          9.10       NaN   \n",
      "6        id01 2024-06-26 13:00:00        7955.0         13.51       NaN   \n",
      "7        id01 2024-06-26 13:10:00      490306.0         11.97       NaN   \n",
      "8        id01 2024-06-26 13:20:00      599985.0          7.70  0.017129   \n",
      "9        id01 2024-06-26 13:30:00      212438.0          7.70       NaN   \n",
      "10       id01 2024-06-26 13:40:00           NaN          7.70       NaN   \n",
      "11       id01 2024-06-26 13:50:00      118178.0          7.70       NaN   \n",
      "12       id01 2024-06-26 14:00:00      221610.0         10.92       NaN   \n",
      "13       id01 2024-06-26 14:10:00      139961.0          7.70       NaN   \n",
      "14       id01 2024-06-26 14:20:00      137126.0          7.70  0.000258   \n",
      "15       id01 2024-06-26 14:30:00     1009273.0          7.70  0.014149   \n",
      "16       id01 2024-06-26 14:40:00      211144.0          7.70       NaN   \n",
      "17       id01 2024-06-26 14:50:00           NaN          7.70  0.041060   \n",
      "18       id01 2024-06-26 15:00:00     1011644.0          7.70       NaN   \n",
      "19       id01 2024-06-26 15:10:00      661039.0          7.70  0.041294   \n",
      "\n",
      "     ww_rssi  avg_heart_rate    distance  burned_calories  avg_latitude  \\\n",
      "0   0.202476             NaN    0.000000         0.000000      0.207810   \n",
      "1   0.091135             NaN    8.330000         0.000000      0.207854   \n",
      "2   0.063361      123.714957    0.000000         0.000000      0.207862   \n",
      "3   0.005904      104.670028    8.460001         0.620000      0.207864   \n",
      "4   0.035869       93.094518  306.940163        17.380004      0.207821   \n",
      "5   0.038284       78.624181    0.000000         0.000000      0.221348   \n",
      "6   0.003126       88.808333  158.919525         7.500055      0.242561   \n",
      "7   0.005748       97.662034   63.499969         2.590014      0.245561   \n",
      "8   0.005529       90.566102    0.000000         0.000000      0.245513   \n",
      "9   0.007582       82.593475    0.000000         0.000000      0.245464   \n",
      "10  0.003997       79.619294    0.000000         0.000000      0.245335   \n",
      "11  0.014741       78.946667    0.000000         0.000000      0.245498   \n",
      "12  0.027664       84.011751  104.270630         4.920019      0.245736   \n",
      "13  0.011173       83.393842   64.319885         3.199982      0.246050   \n",
      "14  0.021996       79.215000   26.989929         1.280006      0.246028   \n",
      "15  0.018795       73.284548    0.000000         0.000000      0.246030   \n",
      "16  0.012998       72.072006    0.000000         0.000000      0.246049   \n",
      "17  0.018454       72.296130    0.000000         0.000000      0.246031   \n",
      "18  0.026452       73.378559    0.000000         0.000000      0.246027   \n",
      "19  0.020048       69.956667    0.000000         0.000000      0.246045   \n",
      "\n",
      "    avg_longitude  avg_altitude  avg_speed    avg_light  avg_prob_ambience  \n",
      "0        0.169965    110.730303   0.079567          NaN                NaN  \n",
      "1        0.169963    110.718788   0.008615          NaN                NaN  \n",
      "2        0.169972    110.742121   0.003272   380.222222                NaN  \n",
      "3        0.169977    110.725455   0.001903   445.900000                NaN  \n",
      "4        0.169810    109.348509   1.520442   699.500000                NaN  \n",
      "5        0.156797     85.349712   6.074147  1118.700000                NaN  \n",
      "6        0.140515     83.026418   3.483478  2372.100000           0.320634  \n",
      "7        0.139898    110.170106   0.105840   270.900000           0.867759  \n",
      "8        0.139907    116.080379   0.010426   376.900000           0.620026  \n",
      "9        0.139913     85.184167   0.009128   315.400000           0.765143  \n",
      "10       0.139944     80.798788   0.068622   334.800000           0.854844  \n",
      "11       0.139934     79.913636   0.118554   511.500000           0.936828  \n",
      "12       0.139939     61.135626   0.434152   258.200000           0.292538  \n",
      "13       0.139944     77.029238   0.264471   172.200000           0.017421  \n",
      "14       0.139930     77.054143   0.630031   198.900000           0.038770  \n",
      "15       0.139938     77.036000   0.557106   196.400000           0.111277  \n",
      "16       0.139942     77.048333   0.093959    74.000000           0.495673  \n",
      "17       0.139930     77.052333   0.557179    61.666667           0.209543  \n",
      "18       0.139933     77.062381   0.739143   142.300000           0.008401  \n",
      "19       0.139937     77.027679   0.379836   114.200000           0.055261  \n"
     ]
    }
   ],
   "source": [
    "print(merge_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1368cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
