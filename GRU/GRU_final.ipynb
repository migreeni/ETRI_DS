{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ea640b",
   "metadata": {},
   "source": [
    "# Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192db93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ usage 합산 완료\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('merged_df_original.csv')\n",
    "\n",
    "# '캐시워크'부터 '우체국보험'까지의 열 이름 목록 추출\n",
    "start_col = '캐시워크'\n",
    "end_col = '우체국보험'\n",
    "cols_to_sum = df.loc[:, start_col:end_col].columns\n",
    "\n",
    "df['m_usagestats'] = df[cols_to_sum].sum(axis=1)\n",
    "\n",
    "df.drop(columns=cols_to_sum, inplace=True)\n",
    "\n",
    "merged_df_original = df.copy()\n",
    "\n",
    "merged_df_original.rename(columns={'m_wtb_rssi_x': 'm_wtb_rssi', 'm_wtb_rssi_y': 'm_wtw_rssi'}, inplace=True)\n",
    "\n",
    "\n",
    "print(\"✅ usage 합산 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf77b0",
   "metadata": {},
   "source": [
    "### Filling zero values for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b816ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>met_activity</th>\n",
       "      <th>m_wtb_rssi</th>\n",
       "      <th>m_wtw_rssi</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>burned_calories</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>id02</th>\n",
       "      <th>id03</th>\n",
       "      <th>id04</th>\n",
       "      <th>id05</th>\n",
       "      <th>id06</th>\n",
       "      <th>id07</th>\n",
       "      <th>id08</th>\n",
       "      <th>id09</th>\n",
       "      <th>id10</th>\n",
       "      <th>m_usagestats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:00:00</td>\n",
       "      <td>6.16</td>\n",
       "      <td>0.102155</td>\n",
       "      <td>0.202476</td>\n",
       "      <td>121.781354</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207832</td>\n",
       "      <td>0.169962</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:10:00</td>\n",
       "      <td>7.84</td>\n",
       "      <td>0.102155</td>\n",
       "      <td>0.091135</td>\n",
       "      <td>121.781354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207858</td>\n",
       "      <td>0.169967</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:20:00</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.098621</td>\n",
       "      <td>0.063361</td>\n",
       "      <td>121.781354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207863</td>\n",
       "      <td>0.169975</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:30:00</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.037712</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>91.059545</td>\n",
       "      <td>108.830027</td>\n",
       "      <td>5.990001</td>\n",
       "      <td>0.207815</td>\n",
       "      <td>0.169852</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:40:00</td>\n",
       "      <td>13.23</td>\n",
       "      <td>0.027420</td>\n",
       "      <td>0.035869</td>\n",
       "      <td>89.132540</td>\n",
       "      <td>206.570137</td>\n",
       "      <td>12.010003</td>\n",
       "      <td>0.209973</td>\n",
       "      <td>0.168650</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id            timestamp  met_activity  m_wtb_rssi  m_wtw_rssi  \\\n",
       "0       id01  2024-06-26 12:00:00          6.16    0.102155    0.202476   \n",
       "1       id01  2024-06-26 12:10:00          7.84    0.102155    0.091135   \n",
       "2       id01  2024-06-26 12:20:00          7.70    0.098621    0.063361   \n",
       "3       id01  2024-06-26 12:30:00          7.70    0.037712    0.005904   \n",
       "4       id01  2024-06-26 12:40:00         13.23    0.027420    0.035869   \n",
       "\n",
       "   heart_rate    distance  burned_calories  latitude  longitude  ...  id02  \\\n",
       "0  121.781354    8.330000         0.000000  0.207832   0.169962  ...     0   \n",
       "1  121.781354    0.000000         0.000000  0.207858   0.169967  ...     0   \n",
       "2  121.781354    0.000000         0.000000  0.207863   0.169975  ...     0   \n",
       "3   91.059545  108.830027         5.990001  0.207815   0.169852  ...     0   \n",
       "4   89.132540  206.570137        12.010003  0.209973   0.168650  ...     0   \n",
       "\n",
       "   id03  id04  id05  id06  id07  id08  id09  id10  m_usagestats  \n",
       "0     0     0     0     0     0     0     0     0           0.0  \n",
       "1     0     0     0     0     0     0     0     0           0.0  \n",
       "2     0     0     0     0     0     0     0     0           0.0  \n",
       "3     0     0     0     0     0     0     0     0           0.0  \n",
       "4     0     0     0     0     0     0     0     0           0.0  \n",
       "\n",
       "[5 rows x 541 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#대상 열 목록\n",
    "cols_to_check = [\n",
    "    'met_activity', 'm_wtb_rssi', 'm_wtw_rssi', 'heart_rate',\n",
    "    'distance', 'latitude', 'longitude', 'altitude', 'speed', 'm_usagestats', 'w_light'\n",
    "]\n",
    "\n",
    "# 결측치 보간 함수 (앞뒤 평균)\n",
    "def fill_nearest_avg(series):\n",
    "    forward = series.ffill()  # 앞쪽 값으로 채우기\n",
    "    backward = series.bfill()  # 뒤쪽 값으로 채우기\n",
    "    filled = series.copy()\n",
    "    \n",
    "    # 앞뒤 값이 모두 있는 경우 평균으로\n",
    "    for i in series[series.isnull()].index:\n",
    "        f, b = forward[i], backward[i]\n",
    "        if pd.notnull(f) and pd.notnull(b):\n",
    "            filled[i] = (f + b) / 2\n",
    "        elif pd.notnull(f):\n",
    "            filled[i] = f\n",
    "        elif pd.notnull(b):\n",
    "            filled[i] = b\n",
    "    return filled\n",
    "\n",
    "# 'burned_calories' 열의 결측치를 0으로 채우기\n",
    "merged_df_original['burned_calories'] = merged_df_original['burned_calories'].fillna(0)\n",
    "\n",
    "# 각 열에 대해 결측치 처리\n",
    "for col in cols_to_check:\n",
    "    merged_df_original[col] = fill_nearest_avg(merged_df_original[col])\n",
    "\n",
    "merged_df_original.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40a9c202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 결측치를 0으로 채운 파일 저장 완료: merged_df_original_tozero.csv\n"
     ]
    }
   ],
   "source": [
    "remaining_cols = [col for col in merged_df_original.columns if col not in cols_to_check]\n",
    "\n",
    "df_original = merged_df_original.copy()\n",
    "df_original = df_original[remaining_cols].fillna(0)\n",
    "df_original.to_csv('merged_df_original_tozero.csv')\n",
    "print(\"✅ 결측치를 0으로 채운 파일 저장 완료: merged_df_original_tozero.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a9760f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>burned_calories</th>\n",
       "      <th>Music</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Motor vehicle (road)</th>\n",
       "      <th>Outside, urban or manmade</th>\n",
       "      <th>Outside, rural or natural</th>\n",
       "      <th>Car</th>\n",
       "      <th>Speech</th>\n",
       "      <th>...</th>\n",
       "      <th>id01</th>\n",
       "      <th>id02</th>\n",
       "      <th>id03</th>\n",
       "      <th>id04</th>\n",
       "      <th>id05</th>\n",
       "      <th>id06</th>\n",
       "      <th>id07</th>\n",
       "      <th>id08</th>\n",
       "      <th>id09</th>\n",
       "      <th>id10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:10:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:20:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:30:00</td>\n",
       "      <td>5.990001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26 12:40:00</td>\n",
       "      <td>12.010003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 530 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id            timestamp  burned_calories  Music  Vehicle  \\\n",
       "0       id01  2024-06-26 12:00:00         0.000000    0.0      0.0   \n",
       "1       id01  2024-06-26 12:10:00         0.000000    0.0      0.0   \n",
       "2       id01  2024-06-26 12:20:00         0.000000    0.0      0.0   \n",
       "3       id01  2024-06-26 12:30:00         5.990001    0.0      0.0   \n",
       "4       id01  2024-06-26 12:40:00        12.010003    0.0      0.0   \n",
       "\n",
       "   Motor vehicle (road)  Outside, urban or manmade  Outside, rural or natural  \\\n",
       "0                   0.0                        0.0                        0.0   \n",
       "1                   0.0                        0.0                        0.0   \n",
       "2                   0.0                        0.0                        0.0   \n",
       "3                   0.0                        0.0                        0.0   \n",
       "4                   0.0                        0.0                        0.0   \n",
       "\n",
       "   Car  Speech  ...  id01  id02  id03  id04  id05  id06  id07  id08  id09  \\\n",
       "0  0.0     0.0  ...     1     0     0     0     0     0     0     0     0   \n",
       "1  0.0     0.0  ...     1     0     0     0     0     0     0     0     0   \n",
       "2  0.0     0.0  ...     1     0     0     0     0     0     0     0     0   \n",
       "3  0.0     0.0  ...     1     0     0     0     0     0     0     0     0   \n",
       "4  0.0     0.0  ...     1     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   id10  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "\n",
       "[5 rows x 530 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a50a5a",
   "metadata": {},
   "source": [
    "# Train & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "754e338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('../ch2025_metrics_train.csv')\n",
    "testset = pd.read_csv('../ch2025_submission_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e6b608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset_q1 head:\n",
      "  subject_id  sleep_date lifelog_date  Q1\n",
      "0       id01  2024-06-27   2024-06-26   0\n",
      "1       id01  2024-06-28   2024-06-27   0\n",
      "2       id01  2024-06-29   2024-06-28   1\n",
      "3       id01  2024-06-30   2024-06-29   1\n",
      "4       id01  2024-07-01   2024-06-30   0\n",
      "trainset_q2 head:\n",
      "  subject_id  sleep_date lifelog_date  Q2\n",
      "0       id01  2024-06-27   2024-06-26   0\n",
      "1       id01  2024-06-28   2024-06-27   0\n",
      "2       id01  2024-06-29   2024-06-28   0\n",
      "3       id01  2024-06-30   2024-06-29   0\n",
      "4       id01  2024-07-01   2024-06-30   1\n",
      "trainset_q3 head:\n",
      "  subject_id  sleep_date lifelog_date  Q3\n",
      "0       id01  2024-06-27   2024-06-26   0\n",
      "1       id01  2024-06-28   2024-06-27   0\n",
      "2       id01  2024-06-29   2024-06-28   0\n",
      "3       id01  2024-06-30   2024-06-29   1\n",
      "4       id01  2024-07-01   2024-06-30   1\n",
      "trainset_s1 head:\n",
      "  subject_id  sleep_date lifelog_date  S1\n",
      "0       id01  2024-06-27   2024-06-26   0\n",
      "1       id01  2024-06-28   2024-06-27   0\n",
      "2       id01  2024-06-29   2024-06-28   1\n",
      "3       id01  2024-06-30   2024-06-29   2\n",
      "4       id01  2024-07-01   2024-06-30   1\n",
      "trainset_s2 head:\n",
      "  subject_id  sleep_date lifelog_date  S2\n",
      "0       id01  2024-06-27   2024-06-26   0\n",
      "1       id01  2024-06-28   2024-06-27   1\n",
      "2       id01  2024-06-29   2024-06-28   1\n",
      "3       id01  2024-06-30   2024-06-29   0\n",
      "4       id01  2024-07-01   2024-06-30   1\n",
      "trainset_s3 head:\n",
      "  subject_id  sleep_date lifelog_date  S3\n",
      "0       id01  2024-06-27   2024-06-26   1\n",
      "1       id01  2024-06-28   2024-06-27   1\n",
      "2       id01  2024-06-29   2024-06-28   1\n",
      "3       id01  2024-06-30   2024-06-29   0\n",
      "4       id01  2024-07-01   2024-06-30   1\n"
     ]
    }
   ],
   "source": [
    "# Define metric columns\n",
    "metrics = ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']\n",
    "\n",
    "# Split df_train and df_val for each metric\n",
    "for metric in metrics:\n",
    "    globals()[f'trainset_{metric.lower()}'] = trainset[['subject_id', 'sleep_date', 'lifelog_date', metric]].copy()\n",
    "\n",
    "# Display head of all 12 dataframes\n",
    "for metric in metrics:\n",
    "    print(f\"trainset_{metric.lower()} head:\")\n",
    "    print(globals()[f'trainset_{metric.lower()}'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a534c0",
   "metadata": {},
   "source": [
    "# GRU\n",
    "- data : merged_df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f08800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Q1 training ===\n",
      "Fold 1 - Best F1: 0.5998 @ Epoch 8\n",
      "Fold 2 - Best F1: 0.5436 @ Epoch 26\n",
      "Fold 3 - Best F1: 0.5181 @ Epoch 5\n",
      "Fold 4 - Best F1: 0.4436 @ Epoch 3\n",
      "Fold 5 - Best F1: 0.5955 @ Epoch 31\n",
      "\n",
      "=== Q2 training ===\n",
      "Fold 1 - Best F1: 0.4665 @ Epoch 13\n",
      "Fold 2 - Best F1: 0.6185 @ Epoch 29\n",
      "Fold 3 - Best F1: 0.6087 @ Epoch 38\n",
      "Fold 4 - Best F1: 0.5799 @ Epoch 42\n",
      "Fold 5 - Best F1: 0.5232 @ Epoch 19\n",
      "\n",
      "=== Q3 training ===\n",
      "Fold 1 - Best F1: 0.5111 @ Epoch 24\n",
      "Fold 2 - Best F1: 0.4877 @ Epoch 32\n",
      "Fold 3 - Best F1: 0.4656 @ Epoch 16\n",
      "Fold 4 - Best F1: 0.4535 @ Epoch 48\n",
      "Fold 5 - Best F1: 0.5374 @ Epoch 18\n",
      "\n",
      "=== S1 training ===\n",
      "Fold 1 - Best F1: 0.4552 @ Epoch 18\n",
      "Fold 2 - Best F1: 0.3842 @ Epoch 13\n",
      "Fold 3 - Best F1: 0.3634 @ Epoch 1\n",
      "Fold 4 - Best F1: 0.3763 @ Epoch 5\n",
      "Fold 5 - Best F1: 0.3381 @ Epoch 3\n",
      "\n",
      "=== S2 training ===\n",
      "Fold 1 - Best F1: 0.4785 @ Epoch 12\n",
      "Fold 2 - Best F1: 0.5505 @ Epoch 39\n",
      "Fold 3 - Best F1: 0.5264 @ Epoch 3\n",
      "Fold 4 - Best F1: 0.7637 @ Epoch 8\n",
      "Fold 5 - Best F1: 0.5773 @ Epoch 32\n",
      "\n",
      "=== S3 training ===\n",
      "Fold 1 - Best F1: 0.4250 @ Epoch 44\n",
      "Fold 2 - Best F1: 0.5436 @ Epoch 4\n",
      "Fold 3 - Best F1: 0.5348 @ Epoch 1\n",
      "Fold 4 - Best F1: 0.4507 @ Epoch 48\n",
      "Fold 5 - Best F1: 0.4871 @ Epoch 10\n",
      "✅ submission saved -> ../results/sub_original_GRU.csv\n"
     ]
    }
   ],
   "source": [
    "import os, copy, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# Preprocess\n",
    "TARGETS = ['Q1','Q2','Q3','S1','S2','S3']\n",
    "df_original['timestamp'] = pd.to_datetime(df_original['timestamp'])\n",
    "df_original['lifelog_date'] = df_original['timestamp'].dt.date.astype(str)\n",
    "\n",
    "DROP_COLS = ['timestamp', 'subject_id', 'lifelog_date']\n",
    "SENSOR_COLS = [c for c in df_original.columns if c not in DROP_COLS]\n",
    "MAX_SEQ = 144\n",
    "\n",
    "def build_sequences(df):\n",
    "    seqs = {}\n",
    "    for (sid, day), g in df.groupby(['subject_id', 'lifelog_date']):\n",
    "        g = g.sort_values('timestamp')\n",
    "        x = g[SENSOR_COLS].to_numpy(np.float32)\n",
    "        if len(x) > MAX_SEQ: x = x[:MAX_SEQ]\n",
    "        if len(x) < MAX_SEQ:\n",
    "            x = np.concatenate([x, np.zeros((MAX_SEQ-len(x), x.shape[1]), np.float32)])\n",
    "        seqs[(sid, day)] = x\n",
    "    return seqs\n",
    "\n",
    "SEQ_DICT = build_sequences(df_original)\n",
    "\n",
    "def rows_to_xy(df):\n",
    "    xs, ys, groups = [], [], []\n",
    "    for _, r in df.iterrows():\n",
    "        key = (r.subject_id, r.lifelog_date)\n",
    "        if key not in SEQ_DICT:\n",
    "            continue\n",
    "        xs.append(SEQ_DICT[key])\n",
    "        ys.append(r[TARGETS].to_list())\n",
    "        groups.append(r.subject_id)\n",
    "    return np.stack(xs), np.array(ys, np.int64), np.array(groups)\n",
    "\n",
    "X_all, y_all, group_all = rows_to_xy(trainset)\n",
    "X_test, _, _ = rows_to_xy(testset)\n",
    "\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler().fit(X_all.reshape(-1, X_all.shape[-1]))\n",
    "def scale(x):\n",
    "    shp = x.shape\n",
    "    return scaler.transform(x.reshape(-1, shp[-1])).reshape(shp)\n",
    "\n",
    "X_all = scale(X_all)\n",
    "X_test = scale(X_test)\n",
    "\n",
    "# ------------------------\n",
    "# Dataset / Model\n",
    "# ------------------------\n",
    "class SleepDS(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i] if self.y is None else (self.X[i], self.y[i])\n",
    "\n",
    "class SingleHeadGRU(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, hidden=128, layers=2, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden, layers, batch_first=True, dropout=drop)\n",
    "        self.fc = nn.Linear(hidden, out_dim)\n",
    "    def forward(self, x):\n",
    "        _, h = self.gru(x)\n",
    "        return self.fc(h[-1])\n",
    "\n",
    "# ------------------------\n",
    "# Train per target\n",
    "# ------------------------\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "N_FOLD = 5\n",
    "EPOCH_MAX = 50\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "preds_dict = {}\n",
    "\n",
    "for k, target in enumerate(TARGETS):\n",
    "    print(f\"\\n=== {target} training ===\")\n",
    "    y_target = y_all[:, k]\n",
    "    out_dim = 3 if target == 'S1' else 2\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_epochs = []\n",
    "\n",
    "    gkf = GroupKFold(n_splits=N_FOLD)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(gkf.split(X_all, y_target, group_all)):\n",
    "        model = SingleHeadGRU(X_all.shape[-1], out_dim).to(DEVICE)\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "\n",
    "        best_f1, best_ep, best_state = -1, 0, None\n",
    "        for epoch in range(1, EPOCH_MAX+1):\n",
    "            model.train()\n",
    "            for xb, yb in DataLoader(SleepDS(X_all[tr_idx], y_target[tr_idx]), batch_size=BATCH_SIZE, shuffle=True):\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "            # validation\n",
    "            model.eval()\n",
    "            all_pred, all_true = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in DataLoader(SleepDS(X_all[val_idx], y_target[val_idx]), batch_size=BATCH_SIZE):\n",
    "                    pred = model(xb.to(DEVICE)).argmax(1).cpu().numpy()\n",
    "                    all_pred.extend(pred)\n",
    "                    all_true.extend(yb.numpy())\n",
    "            f1 = f1_score(all_true, all_pred, average='macro')\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_ep = epoch\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        best_epochs.append(best_ep)\n",
    "        print(f\"Fold {fold+1} - Best F1: {best_f1:.4f} @ Epoch {best_ep}\")\n",
    "\n",
    "    # Final train on all data\n",
    "    final_model = SingleHeadGRU(X_all.shape[-1], out_dim).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(final_model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "    loader = DataLoader(SleepDS(X_all, y_target), batch_size=BATCH_SIZE, shuffle=True)\n",
    "    for epoch in range(1, int(round(np.mean(best_epochs)))+1):\n",
    "        final_model.train()\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            pred = final_model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "    # Predict\n",
    "    final_model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb in DataLoader(SleepDS(X_test), batch_size=BATCH_SIZE):\n",
    "            out = final_model(xb.to(DEVICE))\n",
    "            preds.extend(out.argmax(1).cpu().numpy())\n",
    "    preds_dict[target] = preds\n",
    "\n",
    "# ------------------------\n",
    "# Submission\n",
    "# ------------------------\n",
    "sub = testset[['subject_id','sleep_date','lifelog_date']].copy()\n",
    "for t in TARGETS:\n",
    "    sub[t] = preds_dict[t]\n",
    "\n",
    "SAVE_PATH = '../results/sub_original_GRU.csv'\n",
    "sub.to_csv(SAVE_PATH, index=False)\n",
    "print('✅ submission saved ->', SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e57c3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSOR_COLS: ['met_activity', 'm_wtb_rssi_x', 'm_wtb_rssi_y', 'heart_rate', 'distance', 'burned_calories', 'latitude', 'longitude', 'altitude', 'speed', 'w_light', 'total_time', 'weighted_sum', 'id01', 'id02', 'id03', 'id04', 'id05', 'id06', 'id07', 'id08', 'id09', 'id10']\n",
      "df.columns: ['subject_id', 'lifelog_date', 'met_activity', 'm_wtb_rssi_x', 'm_wtb_rssi_y', 'heart_rate', 'distance', 'burned_calories', 'latitude', 'longitude', 'altitude', 'speed', 'w_light', 'total_time', 'weighted_sum', 'id01', 'id02', 'id03', 'id04', 'id05', 'id06', 'id07', 'id08', 'id09', 'id10']\n"
     ]
    }
   ],
   "source": [
    "print(\"SENSOR_COLS:\", SENSOR_COLS)\n",
    "print(\"df.columns:\", df_original.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce725c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wonjun_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
