{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8101d60f",
   "metadata": {},
   "source": [
    "# Baseline Sleep-Quality Prediction (id-wise)\n",
    "이번 노트북은 `merge_df.csv`의 10분 단위 생체 로그 데이터를 일별로 요약하고, 각 `subject_id`별로 별도의 스태킹-배깅 앙상블 모델을 학습해 6개 지표(Q1–Q3, S1–S3)를 예측합니다.\n",
    "\n",
    "**출력**: `Model test_1/baseline_submission_idwise_v2.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b0a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 2.2.2\n",
      "LightGBM version: {'array_api_support': False, 'non_deterministic': False, 'requires_positive_X': False, 'requires_positive_y': False, 'X_types': ['2darray', 'sparse', '1dlabels'], 'poor_score': False, 'no_validation': False, 'multioutput': False, 'allow_nan': True, 'stateless': False, 'multilabel': False, '_skip_test': False, '_xfail_checks': {'check_no_attributes_set_in_init': 'scikit-learn incorrectly asserts that private attributes cannot be set in __init__: (see https://github.com/microsoft/LightGBM/issues/2628)', 'check_sample_weight_equivalence': \"In LightGBM, setting a sample's weight to 0 can produce a different result than omitting the sample. Such samples intentionally still affect count-based measures like 'min_data_in_leaf' (https://github.com/microsoft/LightGBM/issues/5626#issuecomment-1712706678) and the estimated distribution of features for Dataset construction (see https://github.com/microsoft/LightGBM/issues/5553).\", 'check_sample_weight_equivalence_on_dense_data': \"In LightGBM, setting a sample's weight to 0 can produce a different result than omitting the sample. Such samples intentionally still affect count-based measures like 'min_data_in_leaf' (https://github.com/microsoft/LightGBM/issues/5626#issuecomment-1712706678) and the estimated distribution of features for Dataset construction (see https://github.com/microsoft/LightGBM/issues/5553).\", 'check_sample_weight_equivalence_on_sparse_data': \"In LightGBM, setting a sample's weight to 0 can produce a different result than omitting the sample. Such samples intentionally still affect count-based measures like 'min_data_in_leaf' (https://github.com/microsoft/LightGBM/issues/5626#issuecomment-1712706678) and the estimated distribution of features for Dataset construction (see https://github.com/microsoft/LightGBM/issues/5553).\"}, 'multioutput_only': False, 'binary_only': False, 'requires_fit': True, 'preserves_dtype': [<class 'numpy.float64'>], 'requires_y': True, 'pairwise': False}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from inspect import signature\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# config\n",
    "RANDOM_STATE = 42\n",
    "TARGETS = ['Q1','Q2','Q3','S1','S2','S3']\n",
    "NON_FEATURES = ['subject_id','sleep_date','lifelog_date'] + TARGETS\n",
    "print('scikit-learn version:', pd.__version__)\n",
    "print('LightGBM version:', LGBMClassifier()._get_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a5c0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_df: (76753, 15)\n",
      "train_lbl: (450, 9)\n",
      "test_tpl : (250, 9)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 2) 데이터 로드 및 확인\n",
    "merge_df = pd.read_csv('merge_df.csv')\n",
    "train_lbl = pd.read_csv('ch2025_metrics_train.csv')\n",
    "test_tpl  = pd.read_csv('ch2025_submission_sample.csv')\n",
    "\n",
    "print('merge_df:', merge_df.shape)\n",
    "print('train_lbl:', train_lbl.shape)\n",
    "print('test_tpl :', test_tpl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3cf7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject_id  sleep_date lifelog_date\n",
      "0       id01  2024-06-27   2024-06-26\n",
      "1       id01  2024-06-28   2024-06-27\n",
      "2       id01  2024-06-29   2024-06-28\n",
      "3       id01  2024-06-30   2024-06-29\n",
      "4       id01  2024-07-01   2024-06-30\n"
     ]
    }
   ],
   "source": [
    "# 날짜 column 형식\n",
    "for df in (train_lbl, test_tpl):\n",
    "    for col in ['lifelog_date','sleep_date']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce').dt.date\n",
    "\n",
    "print(train_lbl[['subject_id','sleep_date','lifelog_date']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a36cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(709, 67)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>lifelog_date</th>\n",
       "      <th>avg_altitude_mean</th>\n",
       "      <th>avg_altitude_std</th>\n",
       "      <th>avg_altitude_min</th>\n",
       "      <th>avg_altitude_max</th>\n",
       "      <th>avg_altitude_sum</th>\n",
       "      <th>avg_heart_rate_mean</th>\n",
       "      <th>avg_heart_rate_std</th>\n",
       "      <th>avg_heart_rate_min</th>\n",
       "      <th>...</th>\n",
       "      <th>wb_rssi_mean</th>\n",
       "      <th>wb_rssi_std</th>\n",
       "      <th>wb_rssi_min</th>\n",
       "      <th>wb_rssi_max</th>\n",
       "      <th>wb_rssi_sum</th>\n",
       "      <th>ww_rssi_mean</th>\n",
       "      <th>ww_rssi_std</th>\n",
       "      <th>ww_rssi_min</th>\n",
       "      <th>ww_rssi_max</th>\n",
       "      <th>ww_rssi_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>89.777746</td>\n",
       "      <td>13.057159</td>\n",
       "      <td>61.135626</td>\n",
       "      <td>116.080379</td>\n",
       "      <td>6284.442204</td>\n",
       "      <td>85.659264</td>\n",
       "      <td>10.873441</td>\n",
       "      <td>68.420367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>0.021593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098621</td>\n",
       "      <td>0.943474</td>\n",
       "      <td>0.037841</td>\n",
       "      <td>0.039018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207389</td>\n",
       "      <td>2.648902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>92.761131</td>\n",
       "      <td>13.898336</td>\n",
       "      <td>62.496463</td>\n",
       "      <td>139.125076</td>\n",
       "      <td>13357.602887</td>\n",
       "      <td>85.506998</td>\n",
       "      <td>9.485955</td>\n",
       "      <td>65.372542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008720</td>\n",
       "      <td>0.017648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099395</td>\n",
       "      <td>1.255674</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>0.039301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164983</td>\n",
       "      <td>5.086907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>91.184423</td>\n",
       "      <td>12.080225</td>\n",
       "      <td>73.600027</td>\n",
       "      <td>104.287955</td>\n",
       "      <td>13039.372422</td>\n",
       "      <td>79.135191</td>\n",
       "      <td>9.741568</td>\n",
       "      <td>63.520551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007572</td>\n",
       "      <td>0.014130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073282</td>\n",
       "      <td>1.082823</td>\n",
       "      <td>0.032136</td>\n",
       "      <td>0.041206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242190</td>\n",
       "      <td>4.595484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>102.122124</td>\n",
       "      <td>8.322756</td>\n",
       "      <td>75.504083</td>\n",
       "      <td>142.228182</td>\n",
       "      <td>14705.585842</td>\n",
       "      <td>70.529159</td>\n",
       "      <td>13.957800</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044107</td>\n",
       "      <td>0.389517</td>\n",
       "      <td>0.057289</td>\n",
       "      <td>0.050153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253416</td>\n",
       "      <td>8.249561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>108.977957</td>\n",
       "      <td>12.321548</td>\n",
       "      <td>70.263226</td>\n",
       "      <td>130.471290</td>\n",
       "      <td>15692.825775</td>\n",
       "      <td>95.272954</td>\n",
       "      <td>8.469067</td>\n",
       "      <td>78.211111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.011104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062794</td>\n",
       "      <td>0.563095</td>\n",
       "      <td>0.037335</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187816</td>\n",
       "      <td>5.376227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id lifelog_date  avg_altitude_mean  avg_altitude_std  \\\n",
       "0       id01   2024-06-26          89.777746         13.057159   \n",
       "1       id01   2024-06-27          92.761131         13.898336   \n",
       "2       id01   2024-06-28          91.184423         12.080225   \n",
       "3       id01   2024-06-29         102.122124          8.322756   \n",
       "4       id01   2024-06-30         108.977957         12.321548   \n",
       "\n",
       "   avg_altitude_min  avg_altitude_max  avg_altitude_sum  avg_heart_rate_mean  \\\n",
       "0         61.135626        116.080379       6284.442204            85.659264   \n",
       "1         62.496463        139.125076      13357.602887            85.506998   \n",
       "2         73.600027        104.287955      13039.372422            79.135191   \n",
       "3         75.504083        142.228182      14705.585842            70.529159   \n",
       "4         70.263226        130.471290      15692.825775            95.272954   \n",
       "\n",
       "   avg_heart_rate_std  avg_heart_rate_min  ...  wb_rssi_mean  wb_rssi_std  \\\n",
       "0           10.873441           68.420367  ...      0.013478     0.021593   \n",
       "1            9.485955           65.372542  ...      0.008720     0.017648   \n",
       "2            9.741568           63.520551  ...      0.007572     0.014130   \n",
       "3           13.957800           53.000000  ...      0.002705     0.006836   \n",
       "4            8.469067           78.211111  ...      0.003910     0.011104   \n",
       "\n",
       "   wb_rssi_min  wb_rssi_max  wb_rssi_sum  ww_rssi_mean  ww_rssi_std  \\\n",
       "0          0.0     0.098621     0.943474      0.037841     0.039018   \n",
       "1          0.0     0.099395     1.255674      0.035326     0.039301   \n",
       "2          0.0     0.073282     1.082823      0.032136     0.041206   \n",
       "3          0.0     0.044107     0.389517      0.057289     0.050153   \n",
       "4          0.0     0.062794     0.563095      0.037335     0.040901   \n",
       "\n",
       "   ww_rssi_min  ww_rssi_max  ww_rssi_sum  \n",
       "0          0.0     0.207389     2.648902  \n",
       "1          0.0     0.164983     5.086907  \n",
       "2          0.0     0.242190     4.595484  \n",
       "3          0.0     0.253416     8.249561  \n",
       "4          0.0     0.187816     5.376227  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일별 집계\n",
    "def aggregate_lifelog(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    df['lifelog_date'] = df['timestamp'].dt.date\n",
    "    # 센서 컬럼 강제 numeric\n",
    "    exclude = {'subject_id','timestamp','lifelog_date'}\n",
    "    for col in df.columns.difference(exclude):\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    numeric_cols = df.select_dtypes('number').columns.difference(['subject_id'])\n",
    "    agg = df.groupby(['subject_id','lifelog_date'])[numeric_cols] \\\n",
    "             .agg(['mean','std','min','max','sum'])\n",
    "    agg.columns = [f'{c}_{stat}' for c,stat in agg.columns]\n",
    "    return agg.reset_index()\n",
    "\n",
    "\n",
    "lifelog_daily = aggregate_lifelog(merge_df)\n",
    "print(lifelog_daily.shape)\n",
    "lifelog_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44390919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merge: train (450, 74) test (250, 74)\n"
     ]
    }
   ],
   "source": [
    "# Train/Test\n",
    "train = train_lbl.merge(lifelog_daily, on=['subject_id','lifelog_date'], how='left')\n",
    "test  = test_tpl.merge(lifelog_daily, on=['subject_id','lifelog_date'], how='left')\n",
    "print('After merge: train', train.shape, 'test', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5f985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 피처 개수: 65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['avg_altitude_max',\n",
       " 'avg_altitude_mean',\n",
       " 'avg_altitude_min',\n",
       " 'avg_altitude_std',\n",
       " 'avg_altitude_sum']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  피처 선택 및 결측 처리\n",
    "cand_features = train.columns.difference(NON_FEATURES)\n",
    "feature_cols = [c for c in cand_features if not train[c].isna().all()]\n",
    "if not feature_cols:\n",
    "    # 잠깐 오류고치려고 결측치 1로 채움(이거 바꿔야함)\n",
    "    train['bias'] = 1.0\n",
    "    test['bias']  = 1.0\n",
    "    feature_cols = ['bias']\n",
    "print('사용 피처 개수:', len(feature_cols))\n",
    "feature_cols[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aefdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model factory ready\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의 - 4개 stacking\n",
    "def bagging_supports_estimator() -> bool:\n",
    "    return 'estimator' in signature(BaggingClassifier.__init__).parameters\n",
    "\n",
    "def make_ensemble(n_classes: int):\n",
    "    base_learners = [\n",
    "        ('lgb', LGBMClassifier(n_estimators=400, learning_rate=0.05,\n",
    "             objective='multiclass' if n_classes>2 else 'binary',\n",
    "             num_class=n_classes if n_classes>2 else None,\n",
    "             random_state=RANDOM_STATE)),\n",
    "        ('xgb', XGBClassifier(n_estimators=400, learning_rate=0.05,\n",
    "             objective='multi:softprob' if n_classes>2 else 'binary:logistic',\n",
    "             num_class=n_classes if n_classes>2 else None,\n",
    "             eval_metric='mlogloss' if n_classes>2 else 'logloss',\n",
    "             n_jobs=-1, random_state=RANDOM_STATE)),\n",
    "        ('cat', CatBoostClassifier(iterations=400, learning_rate=0.05,\n",
    "             loss_function='MultiClass' if n_classes>2 else 'Logloss',\n",
    "             verbose=0, random_seed=RANDOM_STATE)),\n",
    "        ('ada', AdaBoostClassifier(n_estimators=400, random_state=RANDOM_STATE))\n",
    "    ]\n",
    "    meta = LogisticRegression(max_iter=1000,\n",
    "                              multi_class='multinomial' if n_classes>2 else 'auto',\n",
    "                              n_jobs=-1)\n",
    "    stack = StackingClassifier(estimators=base_learners,\n",
    "                              final_estimator=meta,\n",
    "                              passthrough=True, n_jobs=-1)\n",
    "    pipe = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "                     ('model', stack)])\n",
    "    bag_kwargs = dict(n_estimators=10, max_samples=0.8, bootstrap=True,\n",
    "                      n_jobs=-1, random_state=RANDOM_STATE)\n",
    "    if bagging_supports_estimator():\n",
    "        return BaggingClassifier(estimator=pipe, **bag_kwargs)\n",
    "    else:\n",
    "        return BaggingClassifier(base_estimator=pipe, **bag_kwargs)\n",
    "print('Model factory ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afde9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_models_per_id ready\n"
     ]
    }
   ],
   "source": [
    "# id별 모델 학습 함수 정의\n",
    "def fit_models_per_id(train_df: pd.DataFrame, feature_cols):\n",
    "    models, global_cache = {}, {}\n",
    "    for sid, grp in train_df.groupby('subject_id'):\n",
    "        X_grp = grp[feature_cols]\n",
    "        for tgt in TARGETS:\n",
    "            y = grp[tgt]\n",
    "            if len(grp)<5 or y.nunique()==1:\n",
    "                if tgt not in global_cache:\n",
    "                    gm = make_ensemble(train_df[tgt].nunique())\n",
    "                    gm.fit(train_df[feature_cols], train_df[tgt])\n",
    "                    global_cache[tgt] = gm\n",
    "                models[(sid, tgt)] = global_cache[tgt]\n",
    "            else:\n",
    "                m = make_ensemble(y.nunique())\n",
    "                m.fit(X_grp, y)\n",
    "                models[(sid, tgt)] = m\n",
    "    return models\n",
    "print('fit_models_per_id ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1488ead9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (7,3) could not be broadcast to indexing result of shape (7,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\njoblib.externals.loky.process_executor._RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py\", line 72, in __call__\n    return self.func(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 1282, in cross_val_predict\n    predictions = parallel(\n                  ^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 1390, in _fit_and_predict\n    predictions = _enforce_prediction_order(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 1457, in _enforce_prediction_order\n    predictions_for_all_classes[:, classes] = predictions\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nValueError: shape mismatch: value array of shape (7,3) could not be broadcast to indexing result of shape (7,2)\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 195, in _parallel_build_estimators\n    estimator_fit(X_, y_, **fit_params_)\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py\", line 672, in fit\n    return super().fit(X, y_encoded, sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py\", line 264, in fit\n    predictions = Parallel(n_jobs=self.n_jobs)(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n    yield from self._retrieve()\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1754, in _retrieve\n    self._raise_error_fast()\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1789, in _raise_error_fast\n    error_job.get_result(self.timeout)\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 745, in get_result\n    return self._return_or_raise()\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 763, in _return_or_raise\n    raise self._result\nValueError: shape mismatch: value array of shape (7,3) could not be broadcast to indexing result of shape (7,2)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 학습 및 추론\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m models \u001b[38;5;241m=\u001b[39m fit_models_per_id(train, feature_cols)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# subject_id별로 한꺼번에 예측\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sid \u001b[38;5;129;01min\u001b[39;00m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m, in \u001b[0;36mfit_models_per_id\u001b[1;34m(train_df, feature_cols)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m             m \u001b[38;5;241m=\u001b[39m make_ensemble(y\u001b[38;5;241m.\u001b[39mnunique())\n\u001b[1;32m---> 17\u001b[0m             m\u001b[38;5;241m.\u001b[39mfit(X_grp, y)\n\u001b[0;32m     18\u001b[0m             models[(sid, tgt)] \u001b[38;5;241m=\u001b[39m m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:66\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     69\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     72\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:402\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    399\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    400\u001b[0m     fit_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:545\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, max_depth, check_input, **fit_params)\u001b[0m\n\u001b[0;32m    542\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[1;32m--> 545\u001b[0m all_results \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    546\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parallel_args()\n\u001b[0;32m    547\u001b[0m )(\n\u001b[0;32m    548\u001b[0m     delayed(_parallel_build_estimators)(\n\u001b[0;32m    549\u001b[0m         n_estimators[i],\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    551\u001b[0m         X,\n\u001b[0;32m    552\u001b[0m         y,\n\u001b[0;32m    553\u001b[0m         seeds[starts[i] : starts[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m    554\u001b[0m         total_n_estimators,\n\u001b[0;32m    555\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    556\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    557\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[0;32m    558\u001b[0m     )\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_jobs)\n\u001b[0;32m    560\u001b[0m )\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    564\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[0;32m    565\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: value array of shape (7,3) could not be broadcast to indexing result of shape (7,2)"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 추론\n",
    "models = fit_models_per_id(train, feature_cols)\n",
    "\n",
    "# subject_id별로 한꺼번에 예측\n",
    "for sid in test['subject_id'].unique():\n",
    "    mask    = test['subject_id'] == sid\n",
    "    X_sid   = test.loc[mask, feature_cols]\n",
    "    for tgt in TARGETS:\n",
    "        # predict → 1D array (shape=(n_rows,))\n",
    "        preds = models[(sid, tgt)].predict(X_sid)\n",
    "        test.loc[mask, tgt] = preds\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "sub_cols = ['subject_id','sleep_date','lifelog_date'] + TARGETS\n",
    "out = 'baseline_submission_idwise_v2.csv'\n",
    "test[sub_cols].to_csv(out, index=False)\n",
    "print('Saved:', out)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
